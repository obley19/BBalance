# AI INTERACTION LOG - H·ªÆU
DATE 14/1/2026
ƒê√¢y l√† k·∫ø ho·∫°ch chi ti·∫øt d√†nh cho nh√≥m 3 ng∆∞·ªùi, t·∫≠p trung v√†o chi·∫øn l∆∞·ª£c "Chia ƒë·ªÉ tr·ªã" ƒë·ªÉ x·ª≠ l√Ω kh·ªëi l∆∞·ª£ng 1.000.000 d·ªØ li·ªáu t·ª´ Shopee v√† Tiki, ƒë·∫£m b·∫£o ƒë√°p ·ª©ng c√°c y√™u c·∫ßu kh·∫Øt khe c·ªßa ƒë·ªì √°n.

### 1. Ph√¢n chia vai tr√≤ (Roles)

ƒê·ªÉ t·ªëi ∆∞u, kh√¥ng n√™n chia vi·ªác theo ki·ªÉu "Ng∆∞·ªùi l√†m Shopee, ng∆∞·ªùi l√†m Tiki" ho√†n to√†n, m√† n√™n chia theo **L·ªõp ch·ª©c nƒÉng (Layers)** k·∫øt h·ª£p h·ªó tr·ª£ nhau ch·∫°y tool.

* **Th√†nh vi√™n 1 (Leader/Backend & Crawler Lead):**
* Ch·ªãu tr√°ch nhi·ªám ki·∫øn tr√∫c Crawler (ch·ªëng ch·∫∑n IP, ƒëa lu·ªìng).
* Code thu·∫≠t to√°n l√µi (SPIMI, BM25) ·ªü Milestone 2.
* *Nhi·ªám v·ª• Crawl:* Ph·ª• tr√°ch c√°c danh m·ª•c ƒêi·ªán t·ª≠/C√¥ng ngh·ªá (nhi·ªÅu th√¥ng s·ªë k·ªπ thu·∫≠t).


* **Th√†nh vi√™n 2 (Data Engineer & Tiki Specialist):**
* X·ª≠ l√Ω API c·ªßa Tiki (th∆∞·ªùng d·ªÖ h∆°n Shopee).
* Ph·ª• tr√°ch kh√¢u **Data Cleaning** (l√†m s·∫°ch) v√† **Normalization** (chu·∫©n h√≥a gi√°, t√™n s·∫£n ph·∫©m).
* *Nhi·ªám v·ª• Crawl:* Ph·ª• tr√°ch danh m·ª•c Th·ªùi trang/M·ªπ ph·∫©m.


* **Th√†nh vi√™n 3 (Frontend & AI Engineer):**
* Reverse Engineering API Shopee (Mobile/Web).
* Nghi√™n c·ª©u Vector Search (FAISS/ChromaDB) cho Milestone 3.
* *Nhi·ªám v·ª• Crawl:* Ph·ª• tr√°ch danh m·ª•c Gia d·ª•ng/ƒê·ªùi s·ªëng.



---

### 2. Chi·∫øn l∆∞·ª£c "H·ª£p s·ª©c" Crawl 1 Tri·ªáu D·ªØ Li·ªáu (Milestone 1)

V√¨ 1.000.000 items l√† r·∫•t l·ªõn, n·∫øu d√πng Selenium s·∫Ω kh√¥ng bao gi·ªù k·ªãp. C√°c b·∫°n ph·∫£i d√πng ph∆∞∆°ng ph√°p **Request API** (Gi·∫£ l·∫≠p HTTP Request).

**Quy tr√¨nh ph·ªëi h·ª£p:**

1. **B∆∞·ªõc 1: T√¨m ID danh m·ª•c (Category IDs):**
* C·∫£ nh√≥m c√πng li·ªát k√™ ra kho·∫£ng 20-30 danh m·ª•c l·ªõn (ƒêi·ªán tho·∫°i, Laptop, √Åo thun, N·ªìi chi√™n...).
* Chia danh s√°ch n√†y l√†m 3 ph·∫ßn cho 3 ng∆∞·ªùi.


2. **B∆∞·ªõc 2: Vi·∫øt Core Crawler (Tu·∫ßn 1-2):**
* Vi·∫øt script Python d√πng th∆∞ vi·ªán `requests` ho·∫∑c `aiohttp` (b·∫Øt bu·ªôc d√πng b·∫•t ƒë·ªìng b·ªô - async ƒë·ªÉ nhanh).
* T·∫•n c√¥ng v√†o API l·∫•y danh s√°ch s·∫£n ph·∫©m c·ªßa Shopee/Tiki (th∆∞·ªùng tr·∫£ v·ªÅ JSON), kh√¥ng parse HTML v√¨ r·∫•t ch·∫≠m v√† d·ªÖ l·ªói.


3. **B∆∞·ªõc 3: Ch·∫°y Distributed Crawling (Tu·∫ßn 2-3):**
* **Kh√¥ng ch·∫°y tr√™n 1 m√°y:** C·∫£ 3 th√†nh vi√™n ƒë·ªÅu ph·∫£i treo m√°y ch·∫°y script song song.
* M·ªói ng∆∞·ªùi ch·∫°y tr√™n danh s√°ch Category ID ƒë∆∞·ª£c ph√¢n c√¥ng.
* *M·∫πo:* N·∫øu c√≥ th·ªÉ, h√£y thu√™ 1-2 VPS gi√° r·∫ª (ho·∫∑c d√πng Google Colab b·∫£n Pro) ƒë·ªÉ treo tool 24/7.


4. **B∆∞·ªõc 4: Merge & Deduplicate:**
* Gom file JSONL/Parquet t·ª´ 3 m√°y l·∫°i.
* Th√†nh vi√™n 2 ch·∫°y script l·ªçc tr√πng (Deduplication) d·ª±a tr√™n Product ID ho·∫∑c URL.



---

### 3. L·ªô tr√¨nh chi ti·∫øt 10 tu·∫ßn

#### **Giai ƒëo·∫°n 1: Data Acquisition (Tu·∫ßn 1 - 4) - Quan tr·ªçng nh·∫•t l√∫c n√†y**

* **Tu·∫ßn 1: Setup & PoC (Proof of Concept)**
* T·∫°o Repo GitHub, c·∫•u tr√∫c th∆∞ m·ª•c chu·∫©n theo ƒë·ªÅ b√†i (src, docs...).
* **Th√†nh vi√™n 2 & 3:** T√¨m endpoint API c·ªßa Tiki v√† Shopee. Th·ª≠ crawl 100 s·∫£n ph·∫©m ƒë·∫ßu ti√™n.
* **Th√†nh vi√™n 1:** D·ª±ng khung code Crawler (Input: Category ID -> Output: JSON Lines).


* **Tu·∫ßn 2: Mass Crawling (T·ªïng l·ª±c)**
* M·ªói ng∆∞·ªùi nh·∫≠n 1/3 danh s√°ch danh m·ª•c.
* B·∫Øt ƒë·∫ßu ch·∫°y tool li√™n t·ª•c. M·ª•c ti√™u: M·ªói ng∆∞·ªùi ki·∫øm ƒë∆∞·ª£c ~350.000 items.
* *L∆∞u √Ω:* L∆∞u file d·∫°ng `raw_data_shopee_part1.jsonl`, `raw_data_tiki_part2.jsonl`.


* **Tu·∫ßn 3: Data Processing**
* **Th√†nh vi√™n 2:** Vi·∫øt script chu·∫©n h√≥a d·ªØ li·ªáu (x√≥a icon, html tags, ƒë∆∞a gi√° v·ªÅ d·∫°ng s·ªë int, t√°ch t·ª´ ti·∫øng Vi·ªát d√πng `pyvi` ho·∫∑c `underthesea`).
* G·ªôp d·ªØ li·ªáu l·∫°i xem ƒë·ªß 1 tri·ªáu ch∆∞a. N·∫øu thi·∫øu, ti·∫øp t·ª•c crawl m·ªü r·ªông sang c√°c ng√°ch nh·ªè (ph·ª• ki·ªán, ·ªëp l∆∞ng...).


* **Tu·∫ßn 4: Finalize Milestone 1**
* Ki·ªÉm tra format JSON/Parquet.
* Vi·∫øt b√°o c√°o, c·∫≠p nh·∫≠t `ai_log.md`.
* N·ªôp b√†i Milestone 1.



#### **Giai ƒëo·∫°n 2: Core Search Engine (Tu·∫ßn 5 - 7)**

* **Tu·∫ßn 5: Indexing (SPIMI)**
* **Th√†nh vi√™n 1:** Code thu·∫≠t to√°n SPIMI ƒë·ªÉ t·∫°o Inverted Index t·ª´ 1 tri·ªáu file. Ch√∫ √Ω qu·∫£n l√Ω b·ªô nh·ªõ (RAM) v√¨ index 1 tri·ªáu file kh√° n·∫∑ng.
* **Th√†nh vi√™n 3:** H·ªó tr·ª£ l∆∞u index xu·ªëng ƒëƒ©a (Dictionary file & Postings list file).


* **Tu·∫ßn 6: Ranking (BM25)**
* **Th√†nh vi√™n 2:** Code h√†m t√≠nh TF-IDF v√† BM25 score th·ªß c√¥ng (kh√¥ng d√πng th∆∞ vi·ªán c√≥ s·∫µn nh∆∞ ElasticSearch/Whoosh).
* **Th√†nh vi√™n 1:** T·ªëi ∆∞u t·ªëc ƒë·ªô truy v·∫•n.


* **Tu·∫ßn 7: Console App & N·ªôp Milestone 2**
* Vi·∫øt m·ªôt tool ch·∫°y d√≤ng l·ªánh (CLI) ƒë·ªÉ th·∫ßy c√¥ test: Nh·∫≠p t·ª´ kh√≥a -> Tr·∫£ v·ªÅ Top 10 s·∫£n ph·∫©m + th·ªùi gian ch·∫°y.



#### **Giai ƒëo·∫°n 3: Final Product (Tu·∫ßn 8 - 10)**

* **Tu·∫ßn 8: AI Integration**
* **Th√†nh vi√™n 3:** D√πng model `phobert` ho·∫∑c `sentence-transformers` ƒë·ªÉ t·∫°o vector cho Title s·∫£n ph·∫©m. L∆∞u v√†o FAISS/ChromaDB.
* Th·ª±c hi·ªán Semantic Search (V√≠ d·ª•: Search "d·∫ø y√™u t√°o khuy·∫øt" ra "iPhone").


* **Tu·∫ßn 9: Web Interface & Hybrid Search**
* **Th√†nh vi√™n 2:** D·ª±ng giao di·ªán Web (Streamlit cho nhanh, ho·∫∑c React n·∫øu team gi·ªèi Web).
* **Th√†nh vi√™n 1:** K·∫øt h·ª£p ƒëi·ªÉm s·ªë: `Final_Score = 0.7 * BM25 + 0.3 * Vector_Score`.
* T√≠nh nƒÉng so s√°nh gi√°: N·∫øu t√¨m th·∫•y s·∫£n ph·∫©m gi·ªëng nhau ·ªü Shopee v√† Tiki, hi·ªÉn th·ªã c·∫°nh nhau (D·ª±a tr√™n t√™n gi·ªëng nhau > 90%).


* **Tu·∫ßn 10: Review & Submit**
* Quay video demo.
* Vi·∫øt b√°o c√°o cu·ªëi k·ª≥.
* Ki·ªÉm tra l·∫°i Commit History l·∫ßn cu·ªëi.



### 4. C√°c r·ªßi ro c·∫ßn tr√°nh (D·ª±a tr√™n ƒë·ªÅ b√†i)

1. **V·∫•n ƒë·ªÅ GitHub:** ƒê·ªÅ b√†i y√™u c·∫ßu l·ªãch s·ª≠ commit ƒë·ªÅu ƒë·∫∑n.
* *Gi·∫£i ph√°p:* Code xong 1 ch·ª©c nƒÉng nh·ªè l√† commit ngay. Kh√¥ng ƒë·ª£i cu·ªëi tu·∫ßn m·ªõi commit 1 c·ª•c. M·ªói ng∆∞·ªùi l√†m tr√™n 1 branch (`feature/crawler-shopee`, `feature/indexing`) r·ªìi merge v√†o `main`.


2. **V·∫•n ƒë·ªÅ Shopee ch·∫∑n IP:** Shopee ch·∫∑n r·∫•t r√°t.
* *Gi·∫£i ph√°p:* S·ª≠ d·ª•ng proxy (xoay IP). N·∫øu kh√¥ng c√≥ ti·ªÅn mua proxy, h√£y d√πng m·∫°ng 4G ph√°t t·ª´ ƒëi·ªán tho·∫°i (t·∫Øt b·∫≠t m√°y bay ƒë·ªÉ ƒë·ªïi IP) khi ch·∫°y crawl. Ho·∫∑c crawl ch·∫≠m l·∫°i (delay 2-3 gi√¢y/request).


3. **V·∫•n ƒë·ªÅ "So s√°nh gi√°":**
* ƒê·ªÉ so s√°nh gi√°, b·∫°n ph·∫£i bi·∫øt s·∫£n ph·∫©m A b√™n Shopee l√† s·∫£n ph·∫©m A b√™n Tiki.
* *Gi·∫£i ph√°p ƒë∆°n gi·∫£n:* Trong l√∫c hi·ªÉn th·ªã k·∫øt qu·∫£ t√¨m ki·∫øm, d√πng thu·∫≠t to√°n so kh·ªõp chu·ªói (Levenshtein distance) ƒë·ªÉ g·ª£i √Ω "S·∫£n ph·∫©m t∆∞∆°ng t·ª± tr√™n s√†n kia".



B·∫°n c√≥ mu·ªën m√¨nh h∆∞·ªõng d·∫´n chi ti·∫øt v·ªÅ c·∫•u tr√∫c file JSON (`data schema`) ƒë·ªÉ chu·∫©n b·ªã cho vi·ªác crawl kh√¥ng?
Vi·ªác thi·∫øt k·∫ø **Data Schema** (C·∫•u tr√∫c d·ªØ li·ªáu) ngay t·ª´ ƒë·∫ßu l√† c·ª±c k·ª≥ quan tr·ªçng. N·∫øu m·ªói ng∆∞·ªùi crawl m·ªôt ki·ªÉu (ng∆∞·ªùi ƒë·∫∑t t√™n tr∆∞·ªùng l√† `price`, ng∆∞·ªùi ƒë·∫∑t l√† `gia_ban`), khi g·ªôp 1 tri·ªáu d√≤ng l·∫°i c√°c b·∫°n s·∫Ω m·∫•t r·∫•t nhi·ªÅu th·ªùi gian ƒë·ªÉ s·ª≠a (Data Cleaning nightmare).

D∆∞·ªõi ƒë√¢y l√† c·∫•u tr√∫c JSON chu·∫©n **Unified Schema** (C·∫•u tr√∫c h·ª£p nh·∫•t) m√† c·∫£ 3 th√†nh vi√™n ph·∫£i tu√¢n th·ªß khi vi·∫øt Crawler cho Shopee v√† Tiki.

---

### 1. C·∫•u tr√∫c JSON chu·∫©n (Target Schema)

ƒê√¢y l√† ƒë·ªãnh d·∫°ng cu·ªëi c√πng c·ªßa m·ªói d√≤ng d·ªØ li·ªáu (`record`) sau khi ƒë√£ x·ª≠ l√Ω s∆° b·ªô.

```json
{
  "id": "string",               // ID duy nh·∫•t (V√≠ d·ª•: "tiki_123456" ho·∫∑c "shopee_987_654")
  "platform": "string",         // "shopee" ho·∫∑c "tiki"
  "title": "string",            // T√™n s·∫£n ph·∫©m (ƒê√£ l√†m s·∫°ch s∆°, trim spaces)
  "url": "string",              // Link g·ªëc ƒë·∫øn s·∫£n ph·∫©m
  "image_url": "string",        // Link ·∫£nh thumbnail ch√≠nh
  "price": "integer",           // Gi√° b√°n hi·ªán t·∫°i (VND) - D·∫°ng s·ªë nguy√™n, kh√¥ng c√≥ d·∫•u ch·∫•m/ph·∫©y
  "original_price": "integer",  // Gi√° g·ªëc (ƒë·ªÉ t√≠nh % gi·∫£m gi√°)
  "discount_rate": "float",     // T·ªâ l·ªá gi·∫£m gi√° (0.0 ƒë·∫øn 1.0)
  "rating_average": "float",    // ƒêi·ªÉm ƒë√°nh gi√° (0.0 ƒë·∫øn 5.0)
  "review_count": "integer",    // S·ªë l∆∞·ª£ng review
  "sold_count": "integer",      // S·ªë l∆∞·ª£ng ƒë√£ b√°n
  "brand": "string",            // Th∆∞∆°ng hi·ªáu (Apple, Samsung, No Brand...)
  "category_id": "string",      // ID danh m·ª•c (ƒë·ªÉ ph√¢n lo·∫°i sau n√†y)
  "category_name": "string",    // T√™n danh m·ª•c (V√≠ d·ª•: "ƒêi·ªán tho·∫°i Smartphone")
  "description": "string",      // M√¥ t·∫£ s·∫£n ph·∫©m (Quan tr·ªçng ƒë·ªÉ Indexing)
  "specifications": "object",   // (T√πy ch·ªçn) C√°c th√¥ng s·ªë k·ªπ thu·∫≠t d·∫°ng key-value
  "crawled_at": "timestamp"     // Th·ªùi ƒëi·ªÉm crawl (Unix timestamp ho·∫∑c ISO format)
}

```

---

### 2. Chi·∫øn l∆∞·ª£c Mapping (√Ånh x·∫°) t·ª´ Raw Data

M·ªói s√†n c√≥ t√™n tr∆∞·ªùng kh√°c nhau trong API response. C√°c b·∫°n c·∫ßn code ƒë·ªÉ "h·ª©ng" d·ªØ li·ªáu v√† map v√†o schema chu·∫©n ·ªü tr√™n.

#### **A. ƒê·ªëi v·ªõi TIKI (Th∆∞·ªùng response s·∫°ch h∆°n)**

D·ªØ li·ªáu Tiki th∆∞·ªùng n·∫±m trong field `data` c·ªßa API JSON.

| Tr∆∞·ªùng chu·∫©n (Target) | Mapping t·ª´ Tiki API (Source) | L∆∞u √Ω x·ª≠ l√Ω |
| --- | --- | --- |
| `id` | `"tiki_" + str(item['id'])` | Th√™m ti·ªÅn t·ªë ƒë·ªÉ tr√°nh tr√πng v·ªõi ID Shopee |
| `title` | `item['name']` |  |
| `price` | `item['price']` | Tiki th∆∞·ªùng l√† s·ªë nguy√™n s·∫µn |
| `original_price` | `item['list_price']` | N·∫øu null th√¨ g√°n b·∫±ng price |
| `rating_average` | `item['rating_average']` |  |
| `sold_count` | `item['all_time_quantity_sold']` |  |
| `url` | `https://tiki.vn/p/{id}.html?spid={spid}` | C·∫ßn gh√©p chu·ªói URL th·ªß c√¥ng |
| `description` | `item['description']` ho·∫∑c `item['short_description']` | C·∫ßn strip HTML tags (x√≥a th·∫ª `<p>`, `<br>`) |

#### **B. ƒê·ªëi v·ªõi SHOPEE (Ph·ª©c t·∫°p h∆°n)**

API Shopee th∆∞·ªùng tr·∫£ v·ªÅ m·ªôt c·ª•c `item` ho·∫∑c `items`.

| Tr∆∞·ªùng chu·∫©n (Target) | Mapping t·ª´ Shopee API (Source) | L∆∞u √Ω x·ª≠ l√Ω (**Quan tr·ªçng**) |
| --- | --- | --- |
| `id` | `"shopee_" + str(item['itemid'])` |  |
| `title` | `item['name']` |  |
| `price` | `item['price'] / 100000` | **C·∫£nh b√°o:** Shopee l∆∞u gi√° nh√¢n v·ªõi 100,000 (V√≠ d·ª•: 50k l√† `5000000000`). Ph·∫£i chia ra. |
| `original_price` | `item['price_before_discount'] / 100000` | C≈©ng ph·∫£i chia cho 100,000 |
| `rating_average` | `item['item_rating']['rating_star']` | N·∫±m l·ªìng trong object `item_rating` |
| `sold_count` | `item['historical_sold']` |  |
| `url` | `https://shopee.vn/product/{shopid}/{itemid}` | C·∫ßn c·∫£ `shopid` v√† `itemid` ƒë·ªÉ t·∫°o link |
| `description` | *Th∆∞·ªùng kh√¥ng c√≥ trong API list*, ph·∫£i g·ªçi API detail | ·ªû Milestone 1, n·∫øu g·ªçi API detail cho 1 tri·ªáu item s·∫Ω r·∫•t l√¢u. C√≥ th·ªÉ t·∫°m ch·∫•p nh·∫≠n l·∫•y `name` l√†m content ƒë·ªÉ index n·∫øu kh√¥ng l·∫•y ƒë∆∞·ª£c description. |

---

### 3. L∆∞u tr·ªØ: T·∫°i sao n√™n d√πng JSONL (JSON Lines)?

Kh√¥ng l∆∞u 1 file JSON kh·ªïng l·ªì ch·ª©a array `[...]`. H√£y l∆∞u d·∫°ng **JSONL** (M·ªói d√≤ng l√† 1 object JSON h·ª£p l·ªá).

**V√≠ d·ª• file `data_shopee_part1.jsonl`:**

```json
{"id": "shopee_112233", "platform": "shopee", "title": "iPhone 15 Pro Max", "price": 30000000, ...}
{"id": "shopee_445566", "platform": "shopee", "title": "·ªêp l∆∞ng iPhone", "price": 50000, ...}

```

**L·ª£i √≠ch c·ªßa JSONL:**

1. **Append d·ªÖ d√†ng:** Khi crawler ƒëang ch·∫°y, c·ª© crawl ƒë∆∞·ª£c 1 item l√† ghi n·ªëi ƒëu√¥i (append) v√†o file ngay. N·∫øu m√°y b·ªã crash/m·∫•t ƒëi·ªán, d·ªØ li·ªáu c≈© v·∫´n c√≤n. (File JSON th∆∞·ªùng m√† crash gi·ªØa ch·ª´ng l√† h·ªèng to√†n b·ªô file).
2. **ƒê·ªçc t·ª´ng d√≤ng:** Khi l√†m Indexing (Milestone 2), b·∫°n c√≥ th·ªÉ ƒë·ªçc t·ª´ng d√≤ng (`readline`) thay v√¨ load c·∫£ 1GB v√†o RAM.

### 4. Quy t·∫Øc "Data Cleaning" ngay khi Crawl (Pre-processing)

ƒê·ªÉ gi·∫£m t·∫£i cho Milestone 2, c√°c b·∫°n n√™n "sanitize" d·ªØ li·ªáu ngay khi l·∫•y v·ªÅ:

1. **X√≥a HTML Tags:** Description c·ªßa Tiki/Shopee ch·ª©a ƒë·∫ßy HTML (`<div>`, `<b>`). D√πng regex ho·∫∑c th∆∞ vi·ªán `BeautifulSoup` ƒë·ªÉ l·∫•y `text` thu·∫ßn.
* *Input:* `<div>√Åo thun <b>cotton</b> m√°t l·∫°nh</div>`
* *Output:* `√Åo thun cotton m√°t l·∫°nh`


2. **X·ª≠ l√Ω Text:**
* Chuy·ªÉn v·ªÅ `lowercase` (ch·ªØ th∆∞·ªùng) c√≥ th·ªÉ l√†m sau, nh∆∞ng n√™n x√≥a c√°c k√Ω t·ª± l·∫° (icon m·∫∑t c∆∞·ªùi, emoji) v√¨ n√≥ g√¢y nhi·ªÖu cho thu·∫≠t to√°n t√°ch t·ª´.


3. **Ki·ªÉm tra null:**
* N·∫øu `price` b·ªã null ho·∫∑c b·∫±ng 0 -> **B·ªè qua**, kh√¥ng l∆∞u (R√°c).
* N·∫øu `title` b·ªã r·ªóng -> **B·ªè qua**.



### 5. Code m·∫´u Python ƒë·ªãnh nghƒ©a Class Item

ƒê·ªÉ ƒë·∫£m b·∫£o c·∫£ 3 ng∆∞·ªùi code gi·ªëng nhau, h√£y t·∫°o 1 file `schema.py` d√πng chung:

```python
import json
from dataclasses import dataclass, asdict

@dataclass
class ProductItem:
    id: str
    platform: str
    title: str
    url: str
    image_url: str
    price: int
    original_price: int
    discount_rate: float
    rating_average: float
    review_count: int
    sold_count: int
    brand: str
    category_id: str
    category_name: str
    description: str
    crawled_at: int # timestamp

    def to_json_line(self):
        # Chuy·ªÉn object th√†nh chu·ªói JSON tr√™n 1 d√≤ng
        return json.dumps(asdict(self), ensure_ascii=False)

```

**Next Step:** B·∫°n c√≥ mu·ªën t√¥i cung c·∫•p ƒëo·∫°n code Python m·∫´u s·ª≠ d·ª•ng th∆∞ vi·ªán `requests` ƒë·ªÉ g·ªçi API Shopee/Tiki v√† map v√†o c√°i class `ProductItem` n√†y kh√¥ng? (ƒê·ªÉ test th·ª≠ xem c√≥ l·∫•y ƒë∆∞·ª£c d·ªØ li·ªáu th·∫≠t kh√¥ng).
T√¥i ƒë√£ r√† so√°t k·ªπ l·∫°i. C·∫•u tr√∫c tr∆∞·ªõc ƒë√≥ l√† **T·ªët cho vi·ªác l∆∞u tr·ªØ**, nh∆∞ng ƒë·ªÉ l√†m **Search Engine (M√°y t√¨m ki·∫øm)** t·ªëi ∆∞u cho ƒë·ªì √°n m√¥n h·ªçc (c·∫ßn ch·ª©c nƒÉng l·ªçc, s·∫Øp x·∫øp, ƒë√°nh tr·ªçng s·ªë), th√¨ n√≥ **thi·∫øu 3 y·∫øu t·ªë quan tr·ªçng**.

D∆∞·ªõi ƒë√¢y l√† phi√™n b·∫£n **JSON Schema Final (V2.0)** ƒë√£ ƒë∆∞·ª£c t·ªëi ∆∞u h√≥a cho c·∫£ 3 Milestone (Crawl, Indexing, AI).

### 1. Nh·ªØng ƒëi·ªÉm "Ch√≠ m·∫°ng" c√≤n thi·∫øu ·ªü b·∫£n c≈©

1. **Thi·∫øu th√¥ng tin ƒë·ªãa ƒëi·ªÉm (Location):** Ng∆∞·ªùi mua Shopee/Tiki r·∫•t quan t√¢m h√†ng g·ª≠i t·ª´ ƒë√¢u (H√† N·ªôi, TP.HCM hay Qu·ªëc t·∫ø). N·∫øu thi·∫øu tr∆∞·ªùng n√†y, b·∫°n m·∫•t ƒëi ch·ª©c nƒÉng "L·ªçc theo khu v·ª±c" (Facet Search).
2. **Thi·∫øu uy t√≠n Shop (Shop Credibility):** Search Engine c·∫ßn rank (x·∫øp h·∫°ng) s·∫£n ph·∫©m. S·∫£n ph·∫©m t·ª´ "Shopee Mall" ho·∫∑c "Shop Y√™u Th√≠ch" ph·∫£i ƒë∆∞·ª£c c·ªông ƒëi·ªÉm ∆∞u ti√™n.
3. **Thi·∫øu tr∆∞·ªùng g·ªôp cho Indexing:** Khi l√†m index (Milestone 2), n·∫øu b·∫°n ph·∫£i n·ªëi chu·ªói `title + description` m·ªói l·∫ßn ch·∫°y th√¨ r·∫•t ch·∫≠m. N√™n t√≠nh tr∆∞·ªõc vi·ªác n√†y.

### 2. C·∫•u tr√∫c JSON Ho√†n Ch·ªânh (D√πng c√°i n√†y ƒë·ªÉ Code)

```json
{
  "id": "shopee_123456789",          // String: ID duy nh·∫•t (Prefix s√†n + ID g·ªëc)
  "platform": "shopee",              // String: "shopee" | "tiki"
  "url": "https://shopee.vn/...",    // String: Link s·∫£n ph·∫©m
  
  // --- NH√ìM HI·ªÇN TH·ªä & TEXT (D√πng cho Indexing) ---
  "title": "ƒêi·ªán tho·∫°i iPhone 15...",// String: T√™n s·∫£n ph·∫©m
  "description": "...",              // String: M√¥ t·∫£ (ƒë√£ strip HTML)
  "brand": "Apple",                  // String: Th∆∞∆°ng hi·ªáu (d√πng ƒë·ªÉ Facet)
  "categories": ["ƒêi·ªán t·ª≠", "Mobile"], // Array[String]: Breadcrumb danh m·ª•c (quan tr·ªçng h∆°n 1 category ƒë∆°n l·∫ª)

  // --- NH√ìM GI√Å & S·ªê LI·ªÜU (D√πng cho Ranking/Sorting) ---
  "price": 25000000,                 // Int: Gi√° b√°n hi·ªán t·∫°i (VND)
  "original_price": 28000000,        // Int: Gi√° g·ªëc
  "discount_rate": 0.11,             // Float: % gi·∫£m gi√° (ƒë·ªÉ sort deal h·ªùi)
  "sold_count": 1500,                // Int: S·ªë l∆∞·ª£ng ƒë√£ b√°n (Quan tr·ªçng ƒë·ªÉ t√≠nh ƒë·ªô Hot)
  "review_count": 500,               // Int: S·ªë l∆∞·ª£t review
  "rating_average": 4.8,             // Float: ƒêi·ªÉm sao (0.0 - 5.0)

  // --- NH√ìM L·ªåC & UY T√çN (B·ªï sung m·ªõi) ---
  "inventory_location": "H√† N·ªôi",    // String: N∆°i b√°n (H√† N·ªôi, TP.HCM, Qu·ªëc T·∫ø...)
  "shop_info": {                     // Object: Th√¥ng tin ng∆∞·ªùi b√°n
      "shop_id": "12345",
      "name": "Apple Flagship Store",
      "is_official": true            // Boolean: L√† Shopee Mall / Tiki Trading hay kh√¥ng? (Tr·ªçng s·ªë ranking cao)
  },

  // --- META DATA ---
  "crawled_at": 1705028400           // Int: Unix Timestamp (ƒë·ªÉ bi·∫øt d·ªØ li·ªáu m·ªõi hay c≈©)
}

```

### 3. Gi·∫£i th√≠ch t·∫°i sao c·∫•u tr√∫c n√†y t·ªët h∆°n cho ƒê·ªì √°n?

1. **`is_official` (Boolean):**
* Khi b·∫°n code thu·∫≠t to√°n BM25 k·∫øt h·ª£p tr·ªçng s·ªë (Milestone 2/3), b·∫°n c√≥ th·ªÉ vi·∫øt c√¥ng th·ª©c:
* `Final_Score = BM25_Score + (is_official ? 100 : 0)` -> ƒê·∫©y shop ch√≠nh h√£ng l√™n ƒë·∫ßu trang (gi·ªëng Shopee th·∫≠t).


2. **`categories` (Array):**
* Thay v√¨ `category_id` v√¥ nghƒ©a, h√£y l∆∞u d·∫°ng m·∫£ng t√™n: `["ƒêi·ªán tho·∫°i", "Ph·ª• ki·ªán", "·ªêp l∆∞ng"]`.
* Gi√∫p b·∫°n l√†m t√≠nh nƒÉng **Drill-down Facet** (L·ªçc s√¢u d·∫ßn) b√™n c·ªôt tr√°i giao di·ªán web.


3. **`inventory_location`:**
* Gi·∫£i quy·∫øt b√†i to√°n user ·ªü HN mu·ªën t√¨m h√†ng ·ªü HN ƒë·ªÉ ship nhanh.



### 4. Checklist ki·ªÉm tra d·ªØ li·ªáu ("Definition of Done" cho Milestone 1)

Tr∆∞·ªõc khi 3 ng∆∞·ªùi b·∫Øt ƒë·∫ßu ch·∫°y tool c·∫Øm m√°y crawl, h√£y ƒë·∫£m b·∫£o script crawler tu√¢n th·ªß quy t·∫Øc **Data Validation** n√†y (code trong crawler):

* [ ] **ID Check:** `id` kh√¥ng ƒë∆∞·ª£c Null/Empty.
* [ ] **Price Check:** `price` ph·∫£i l√† s·ªë nguy√™n (Int) > 0. N·∫øu API tr·∫£ v·ªÅ String "1.200.000ƒë" -> Ph·∫£i convert sang `1200000`.
* [ ] **Sanitize Text:** `title` v√† `description` kh√¥ng ƒë∆∞·ª£c ch·ª©a k√Ω t·ª± xu·ªëng d√≤ng `\n` (v√¨ file format l√† JSON Lines, m·ªói d√≤ng 1 item, ƒë·ªÉ `\n` s·∫Ω l√†m g√£y file).
* *Tip:* D√πng `text.replace('\n', ' ').replace('\r', '')`.


* [ ] **Default Value:**
* N·∫øu `rating_average` null -> G√°n m·∫∑c ƒë·ªãnh `0.0`.
* N·∫øu `sold_count` null -> G√°n m·∫∑c ƒë·ªãnh `0`.



### 5. Code Python Mapping (C·∫≠p nh·∫≠t m·ªõi nh·∫•t)

ƒê√¢y l√† Class Python ƒë√£ update theo c·∫•u tr√∫c m·ªõi. B·∫°n copy ƒëo·∫°n n√†y g·ª≠i cho team l√†m "Core".

```python
import json
import time
from dataclasses import dataclass, field
from typing import List, Optional

@dataclass
class ShopInfo:
    shop_id: str
    name: str
    is_official: bool # True n·∫øu l√† Mall/Official/Tiki Trading

@dataclass
class ProductItem:
    id: str
    platform: str
    url: str
    
    # Text Data
    title: str
    description: str
    brand: str
    categories: List[str] # Thay v√¨ category_id ƒë∆°n l·∫ª
    
    # Numeric Data
    price: int
    original_price: int
    discount_rate: float
    sold_count: int
    review_count: int
    rating_average: float
    
    # Filter & Ranking Data
    inventory_location: str
    shop_info: ShopInfo # Nested Object
    
    crawled_at: int = field(default_factory=lambda: int(time.time()))

    def to_json_line(self):
        # Helper ƒë·ªÉ convert object sang dict, r·ªìi sang chu·ªói JSON
        data = self.__dict__.copy()
        # Convert nested object ShopInfo to dict
        if isinstance(self.shop_info, ShopInfo):
            data['shop_info'] = self.shop_info.__dict__
        
        # Quan tr·ªçng: X√≥a k√Ω t·ª± xu·ªëng d√≤ng ƒë·ªÉ ƒë·∫£m b·∫£o ƒë√∫ng format JSONL
        if data['description']:
            data['description'] = data['description'].replace('\n', ' ').replace('\r', '')
            
        return json.dumps(data, ensure_ascii=False)

```

**B·∫°n ƒë√£ s·∫µn s√†ng.** C·∫•u tr√∫c n√†y ƒë·ªß m·∫°nh ƒë·ªÉ x·ª≠ l√Ω 1 tri·ªáu d·ªØ li·ªáu v√† h·ªó tr·ª£ t·ªët cho c·∫£ vi·ªác t√¨m ki·∫øm t·ª´ kh√≥a (Keyword Search) l·∫´n l·ªçc n√¢ng cao.

C√≥ c·∫ßn m√¨nh gi√∫p vi·∫øt lu√¥n ƒëo·∫°n h√†m `def parse_shopee_item(json_data):` ƒë·ªÉ map ƒë√∫ng c√°c tr∆∞·ªùng `inventory_location` v√† `is_official` t·ª´ API Shopee kh√¥ng? (V√¨ API Shopee ƒë·∫∑t t√™n m·∫•y tr∆∞·ªùng n√†y r·∫•t d·ªã).
C√¢u tr·∫£ l·ªùi ng·∫Øn g·ªçn: **C√ì, B·∫ÆT BU·ªòC TUY·ªÜT ƒê·ªêI.**

N·∫øu 3 ng∆∞·ªùi ra 3 ki·ªÉu JSON kh√°c nhau (d√π ch·ªâ sai 1 ch·ªØ c√°i trong t√™n tr∆∞·ªùng), d·ª± √°n c·ªßa b·∫°n s·∫Ω g·∫∑p **th·∫£m h·ªça** khi g·ªôp d·ªØ li·ªáu (Merge Data) ·ªü cu·ªëi Milestone 1.

D∆∞·ªõi ƒë√¢y l√† gi·∫£i th√≠ch t·∫°i sao v√† c√°ch ƒë·ªÉ ƒë·ªìng b·ªô d·ªÖ d√†ng nh·∫•t.

### 1. T·∫°i sao ph·∫£i gi·ªëng y h·ªát nhau?

M√°y t√¨m ki·∫øm (Search Engine) ho·∫°t ƒë·ªông nh∆∞ m·ªôt d√¢y chuy·ªÅn nh√† m√°y:

* **ƒê·∫ßu v√†o:** File d·ªØ li·ªáu th√¥ (JSONL).
* **M√°y x·ª≠ l√Ω:** Code Indexer (thu·∫≠t to√°n SPIMI/BM25).

N·∫øu code Indexer ƒë∆∞·ª£c vi·∫øt ƒë·ªÉ ƒë·ªçc tr∆∞·ªùng `price`, nh∆∞ng d·ªØ li·ªáu t·ª´ √¥ng l√†m Tiki l·∫°i ghi l√† `gia_ban`, th√¨ ch∆∞∆°ng tr√¨nh s·∫Ω b·ªã **Crash (KeyError)** ngay l·∫≠p t·ª©c.

**V√≠ d·ª• v·ªÅ th·∫£m h·ªça:**

* **√îng A (L√†m Shopee):** `{"title": "Iphone", "price": 10tr}`
* **√îng B (L√†m Tiki):** `{"name": "Iphone", "gia_tien": 10tr}` -> **Sai t√™n tr∆∞·ªùng!**
* **√îng C (L√†m Lazada):** `{"title": "Iphone", "price": "10.000.000"}` -> **Sai ki·ªÉu d·ªØ li·ªáu (String vs Int)!**

=> Khi g·ªôp 1 tri·ªáu d√≤ng n√†y v√†o file chung, b·∫°n **kh√¥ng th·ªÉ** vi·∫øt h√†m `sort` hay `search` ƒë∆∞·ª£c v√¨ d·ªØ li·ªáu l·ªôn x·ªôn. L√∫c ƒë√≥ ng·ªìi s·ª≠a l·∫°i 1 tri·ªáu d√≤ng c√≤n kh·ªï h∆°n l√†m l·∫°i t·ª´ ƒë·∫ßu.

### 2. C√°i g√¨ c·∫ßn gi·ªëng, c√°i g√¨ ƒë∆∞·ª£c kh√°c?

Tuy n√≥i l√† "gi·ªëng nhau", nh∆∞ng c·∫ßn ph√¢n bi·ªát r√µ:

* **Logic l·∫•y d·ªØ li·ªáu (ƒê∆Ø·ª¢C KH√ÅC NHAU):**
* Ng∆∞·ªùi l√†m Shopee ph·∫£i code ki·ªÉu Shopee (chia gi√° cho 100000, l·∫•y ID t·ª´ itemid).
* Ng∆∞·ªùi l√†m Tiki ph·∫£i code ki·ªÉu Tiki (l·∫•y ID t·ª´ id).
* *Code x·ª≠ l√Ω b√™n trong v√≤ng l·∫∑p crawl c·ªßa m·ªói ng∆∞·ªùi ch·∫Øc ch·∫Øn s·∫Ω kh√°c nhau.*


* **C·∫•u tr√∫c ƒë·∫ßu ra (B·∫ÆT BU·ªòC GI·ªêNG):**
* D√π logic b√™n tr√™n kh√°c nhau th·∫ø n√†o, th√¨ tr∆∞·ªõc khi `write` xu·ªëng file, c·∫£ 3 ng∆∞·ªùi ph·∫£i n√©m d·ªØ li·ªáu v√†o c√πng 1 c√°i khung (Schema) ƒë√£ th·ªëng nh·∫•t.



### 3. Gi·∫£i ph√°p k·ªπ thu·∫≠t ƒë·ªÉ kh√¥ng bao gi·ªù sai (Best Practice)

ƒê·ª´ng ƒë·ªÉ m·ªói ng∆∞·ªùi t·ª± g√µ tay ch·ªØ `"price"` hay `"title"` v√†o code (d·ªÖ g√µ nh·∫ßm `"titl"` hay `"pice"`).

H√£y t·∫°o m·ªôt file chung, v√≠ d·ª• t√™n l√† **`schema_shared.py`**, v√† 3 ng∆∞·ªùi c√πng `import` file n√†y v√†o code crawler c·ªßa m√¨nh.

**N·ªôi dung file `schema_shared.py` (Ch·ªâ c·∫ßn 1 file n√†y):**

```python
# schema_shared.py
import json

# ƒê·ªãnh nghƒ©a c√°c t√™n tr∆∞·ªùng c·ªë ƒë·ªãnh ƒë·ªÉ kh√¥ng ai g√µ sai
FIELD_ID = "id"
FIELD_PLATFORM = "platform"
FIELD_TITLE = "title"
FIELD_PRICE = "price"
# ... c√°c tr∆∞·ªùng kh√°c

class ProductItem:
    def __init__(self, id, platform, title, price, ...):
        self.data = {
            FIELD_ID: id,
            FIELD_PLATFORM: platform,
            FIELD_TITLE: title,
            FIELD_PRICE: int(price), # √âp ki·ªÉu Int ngay t·∫°i ƒë√¢y ƒë·ªÉ tr√°nh l·ªói
            # ...
        }

    def to_json(self):
        return json.dumps(self.data, ensure_ascii=False)

```

**C√°ch d√πng (C·∫£ 3 ng∆∞·ªùi ƒë·ªÅu code th·∫ø n√†y):**

```python
from schema_shared import ProductItem

# Code crawl Shopee c·ªßa √îng A
item = ProductItem(id="shopee_1", platform="shopee", title="ABC", price=100)
save_to_file(item.to_json())

# Code crawl Tiki c·ªßa √îng B
item = ProductItem(id="tiki_2", platform="tiki", title="XYZ", price=200)
save_to_file(item.to_json())

```

### T√≥m l·∫°i

B·∫°n h√£y copy file `schema.py` (b·∫£n t·ªëi gi·∫£n t√¥i g·ª≠i ·ªü c√¢u tr·∫£ l·ªùi tr∆∞·ªõc), g·ª≠i v√†o nh√≥m chat Zalo/Discord v√† ra l·ªánh: **"T·∫•t c·∫£ anh em ph·∫£i import class n√†y ƒë·ªÉ l∆∞u d·ªØ li·ªáu. C·∫•m t·ª± g√µ tay t√™n tr∆∞·ªùng (key) trong file JSON."**

L√†m ƒë√∫ng b∆∞·ªõc n√†y, vi·ªác gh√©p 1 tri·ªáu d√≤ng d·ªØ li·ªáu ch·ªâ m·∫•t 5 gi√¢y copy-paste file.
ƒê√¢y l√† quy tr√¨nh t√°c chi·∫øn c·ª• th·ªÉ ("Battle Plan") ƒë·ªÉ b·∫°n copy v√† paste v√†o nh√≥m chat ngay l·∫≠p t·ª©c. M·ª•c ti√™u l√† ƒë·∫£m b·∫£o 3 ng∆∞·ªùi l√†m vi·ªác ƒë·ªôc l·∫≠p nh∆∞ng k·∫øt qu·∫£ r√°p l·∫°i kh·ªõp 100%.

---

### B∆Ø·ªöC 1: PH√ÇN CHIA "L√ÉNH TH·ªî" (ƒê·ªÉ kh√¥ng ai crawl tr√πng ai)

V√¨ m·ª•c ti√™u l√† 1.000.000 s·∫£n ph·∫©m, c√°c b·∫°n kh√¥ng n√™n crawl lung tung. H√£y chia theo **Category (Danh m·ª•c ng√†nh h√†ng)**.

**Ph√¢n c√¥ng (V√≠ d·ª•):**

* **Th√†nh vi√™n 1 (√îng A): Ph·ª• tr√°ch ƒë·ªì C√îNG NGH·ªÜ & ƒêI·ªÜN T·ª¨**
* **Nhi·ªám v·ª•:** Crawl ƒêi·ªán tho·∫°i, Laptop, M√°y ·∫£nh, Ph·ª• ki·ªán s·ªë, Tivi, Loa ƒë√†i... tr√™n c·∫£ Shopee v√† Tiki.


* **Th√†nh vi√™n 2 (√îng B): Ph·ª• tr√°ch ƒë·ªì TH·ªúI TRANG & L√ÄM ƒê·∫∏P**
* **Nhi·ªám v·ª•:** Crawl Qu·∫ßn √°o, Gi√†y d√©p, ƒê·ªìng h·ªì, M·ªπ ph·∫©m, Skincare... tr√™n c·∫£ Shopee v√† Tiki.


* **Th√†nh vi√™n 3 (√îng C): Ph·ª• tr√°ch ƒë·ªì GIA D·ª§NG & ƒê·ªúI S·ªêNG**
* **Nhi·ªám v·ª•:** Crawl ƒê·ªì b·∫øp, N·ªôi th·∫•t, S√°ch, VƒÉn ph√≤ng ph·∫©m, M·∫π & B√©, B√°ch h√≥a... tr√™n c·∫£ Shopee v√† Tiki.



---

### B∆Ø·ªöC 2: QUY TR√åNH CRAWL C·ª§ TH·ªÇ CHO T·ª™NG TH√ÄNH VI√äN

M·ªói th√†nh vi√™n s·∫Ω th·ª±c hi·ªán ƒë√∫ng 3 vi·ªác sau tr√™n m√°y c·ªßa m√¨nh:

#### 1. L·∫•y Category ID (Input)

Tr∆∞·ªõc khi ch·∫°y code, b·∫°n c·∫ßn bi·∫øt ID c·ªßa danh m·ª•c m√¨nh ph·ª• tr√°ch.

* **C√°ch l·∫•y tr√™n Tiki:** V√†o web tiki, b·∫•m v√†o danh m·ª•c (v√≠ d·ª• "ƒêi·ªán tho·∫°i"), nh√¨n tr√™n URL: `tiki.vn/dien-thoai-may-tinh-bang/c1789`. -> ID l√† `1789`.
* **C√°ch l·∫•y tr√™n Shopee:** V√†o web shopee, b·∫•m v√†o danh m·ª•c, nh√¨n URL: `shopee.vn/Dien-Thoai-Phu-Kien-cat.11036030`. -> ID l√† `11036030`. (Ho·∫∑c d√πng F12 -> Network tab ƒë·ªÉ soi API `get_items`).

#### 2. D√°n ƒëo·∫°n Code Schema v√†o Project (B·∫ÆT BU·ªòC)

T·∫°o file `schema.py` ch·ª©a ƒëo·∫°n code Class `ProductPriceItem` (ƒë√£ ch·ªët ·ªü tr√™n). T·∫•t c·∫£ file crawler ph·∫£i `import` file n√†y.

#### 3. Code logic "Mapping" (Ph·∫ßn quan tr·ªçng nh·∫•t)

ƒê√¢y l√† ƒëo·∫°n code chuy·ªÉn ƒë·ªïi d·ªØ li·ªáu th√¥ t·ª´ Shopee/Tiki sang chu·∫©n chung c·ªßa nh√≥m.

**A. N·∫øu b·∫°n ƒëang Crawl SHOPEE:**
Copy ƒëo·∫°n n√†y v√†o v√≤ng l·∫∑p x·ª≠ l√Ω items c·ªßa Shopee:

```python
# Gi·∫£ s·ª≠ 'item' l√† 1 dictionary l·∫•y t·ª´ API Shopee v·ªÅ
# API Shopee th∆∞·ªùng tr·∫£ v·ªÅ: itemid, name, price (x100000), brand, catid...

def map_shopee_item(item, category_name):
    # 1. X·ª≠ l√Ω gi√° (Shopee nh√¢n gi√° v·ªõi 100,000)
    real_price = int(item.get('price', 0) / 100000)
    original_price = int(item.get('price_before_discount', 0) / 100000)
    if original_price == 0: original_price = real_price

    # 2. X·ª≠ l√Ω Brand (N·∫øu null th√¨ ƒë·ªÉ No Brand)
    brand = item.get('brand', 'No Brand')
    if brand is None: brand = "No Brand"

    # 3. T·∫°o Object chu·∫©n
    product = ProductPriceItem(
        id=f"shopee_{item['itemid']}",       # Prefix ƒë·ªÉ kh√¥ng tr√πng
        platform="shopee",
        title=item['name'],
        price=real_price,
        original_price=original_price,
        url=f"https://shopee.vn/product/{item['shopid']}/{item['itemid']}",
        image_url=f"https://cf.shopee.vn/file/{item['image']}",
        category=category_name,              # V√≠ d·ª•: "ƒêi·ªán tho·∫°i"
        brand=brand
    )
    return product.to_json_line()

```

**B. N·∫øu b·∫°n ƒëang Crawl TIKI:**
Copy ƒëo·∫°n n√†y v√†o v√≤ng l·∫∑p x·ª≠ l√Ω items c·ªßa Tiki:

```python
# Gi·∫£ s·ª≠ 'item' l√† 1 dictionary l·∫•y t·ª´ API Tiki v·ªÅ

def map_tiki_item(item, category_name):
    # Tiki gi√° th∆∞·ªùng chu·∫©n, kh√¥ng c·∫ßn chia
    
    # T·∫°o Object chu·∫©n
    product = ProductPriceItem(
        id=f"tiki_{item['id']}",             # Prefix
        platform="tiki",
        title=item['name'],
        price=int(item.get('price', 0)),
        original_price=int(item.get('list_price', item.get('price', 0))),
        url=f"https://tiki.vn/{item.get('url_path', '')}",
        image_url=item.get('thumbnail_url', ''),
        category=category_name,
        brand=item.get('brand_name', 'No Brand')
    )
    return product.to_json_line()

```

---

### B∆Ø·ªöC 3: XU·∫§T FILE & G·ªòP D·ªÆ LI·ªÜU

Sau khi ch·∫°y xong, m·ªói ng∆∞·ªùi s·∫Ω c√≥ c√°c file ri√™ng l·∫ª. H√£y ƒë·∫∑t t√™n file theo quy t·∫Øc:
`data_{T√äN_NG∆Ø·ªúI}_{S√ÄN}_{DANH_M·ª§C}.jsonl`

**V√≠ d·ª•:**

* `data_Huy_Shopee_Dienthoai.jsonl`
* `data_Huy_Tiki_Laptop.jsonl`
* `data_Tuan_Shopee_Thoitrang.jsonl`

**Cu·ªëi tu·∫ßn:**

1. C·∫£ 3 ng∆∞·ªùi upload file l√™n Google Drive chung.
2. Tr∆∞·ªüng nh√≥m t·∫£i h·∫øt v·ªÅ.
3. Ch·∫°y l·ªánh g·ªôp (tr√™n Windows CMD):
`type *.jsonl > all_data_merged.jsonl`
4. L√∫c n√†y c√°c b·∫°n s·∫Ω c√≥ file `all_data_merged.jsonl` ch·ª©a 1 tri·ªáu d√≤ng v·ªõi **c·∫•u tr√∫c y h·ªát nhau**, s·∫µn s√†ng ƒë·ªÉ l√†m Search Engine.

**T√≥m l·∫°i:** B·∫°n ch·ªâ c·∫ßn g·ª≠i file `schema.py` v√† c√°i h∆∞·ªõng d·∫´n "Mapping" ·ªü B∆∞·ªõc 2 cho 2 b·∫°n kia l√† xong. Code crawl (request g·ª≠i ƒëi) th√¨ m·ªói ng∆∞·ªùi t·ª± lo, nh∆∞ng d·ªØ li·ªáu ƒë·∫ßu ra ph·∫£i ƒëi qua c√°i ph·ªÖu Mapping n√†y.
Tuy·ªát v·ªùi. B√¢y gi·ªù b·∫°n ƒë√£ c√≥ "c√°i khu√¥n" (`schema_shared.py`), t√¥i s·∫Ω ƒë∆∞a cho b·∫°n "c√°i m√°y d·∫≠p" (`crawler_main.py`).

D∆∞·ªõi ƒë√¢y l√† file code ho√†n ch·ªânh ƒë·ªÉ crawl d·ªØ li·ªáu. ƒê·ªÉ ƒë·∫£m b·∫£o b·∫°n ch·∫°y ƒë∆∞·ª£c ngay ("Quick Win"), t√¥i s·∫Ω vi·∫øt m·∫´u **Crawler cho Tiki** tr∆∞·ªõc (v√¨ API Tiki d·ªÖ th·ªü h∆°n, kh√¥ng ch·∫∑n g·∫Øt nh∆∞ Shopee). Sau ƒë√≥ t√¥i s·∫Ω h∆∞·ªõng d·∫´n ch·ªó ƒë·ªÉ s·ª≠a th√†nh Shopee.

### 1. Chu·∫©n b·ªã th∆∞ m·ª•c

C·∫•u tr√∫c th∆∞ m·ª•c c·ªßa b·∫°n b·∫Øt bu·ªôc ph·∫£i nh∆∞ th·∫ø n√†y th√¨ code m·ªõi ch·∫°y:

```text
Project/
‚îú‚îÄ‚îÄ schema_shared.py   <-- (File b·∫°n v·ª´a t·∫°o ·ªü b∆∞·ªõc tr∆∞·ªõc)
‚îú‚îÄ‚îÄ crawler_main.py    <-- (File t√¥i s·∫Øp ƒë∆∞a d∆∞·ªõi ƒë√¢y)
‚îî‚îÄ‚îÄ data/              <-- (Th∆∞ m·ª•c r·ªóng ƒë·ªÉ ch·ª©a d·ªØ li·ªáu)

```

### 2. N·ªôi dung file `crawler_main.py`

Copy to√†n b·ªô ƒëo·∫°n code d∆∞·ªõi ƒë√¢y:

```python
import requests
import json
import time
import random
import os
from schema_shared import ProductItem

# --- C·∫§U H√åNH ---
DATA_FOLDER = "data"
if not os.path.exists(DATA_FOLDER):
    os.makedirs(DATA_FOLDER)

# Gi·∫£ l·∫≠p tr√¨nh duy·ªát ƒë·ªÉ kh√¥ng b·ªã ch·∫∑n (Fake Headers)
HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Referer': 'https://tiki.vn/',
    'Accept': 'application/json, text/plain, */*',
}

def crawl_tiki_category(category_name, category_id, max_pages=5):
    """
    H√†m crawl m·ªôt danh m·ª•c c·ª• th·ªÉ tr√™n Tiki
    :param category_name: T√™n danh m·ª•c (VD: 'DienThoai') - d√πng ƒë·ªÉ ƒë·∫∑t t√™n file
    :param category_id: ID danh m·ª•c tr√™n Tiki (VD: 1789)
    :param max_pages: S·ªë l∆∞·ª£ng trang mu·ªën crawl
    """
    print(f"üöÄ B·∫Øt ƒë·∫ßu crawl Tiki: {category_name} (ID: {category_id})")
    
    output_file = os.path.join(DATA_FOLDER, f"tiki_{category_name}.jsonl")
    
    # M·ªü file v·ªõi ch·∫ø ƒë·ªô 'a' (append) ƒë·ªÉ ghi n·ªëi ƒëu√¥i
    with open(output_file, 'a', encoding='utf-8') as f:
        
        for page in range(1, max_pages + 1):
            print(f"   ... ƒêang t·∫£i trang {page}/{max_pages}")
            
            # 1. G·ªçi API c·ªßa Tiki (API Mobile r·∫•t nh·∫π v√† nhanh)
            # URL n√†y l·∫•y danh s√°ch s·∫£n ph·∫©m theo category v√† page
            url = f"https://tiki.vn/api/personalish/v1/blocks/listings?limit=40&include=advertisement&aggregations=2&version=home-persionalized&trackity_id=123&category={category_id}&page={page}"
            
            try:
                response = requests.get(url, headers=HEADERS)
                
                if response.status_code != 200:
                    print(f"‚ö†Ô∏è L·ªói HTTP {response.status_code} t·∫°i trang {page}. B·ªè qua.")
                    time.sleep(5) # Ngh·ªâ l√¢u h∆°n n·∫øu g·∫∑p l·ªói
                    continue
                
                data = response.json()
                items = data.get('data', [])
                
                if not items:
                    print("‚ö†Ô∏è H·∫øt s·∫£n ph·∫©m ho·∫∑c b·ªã ch·∫∑n. D·ª´ng crawl.")
                    break

                # 2. X·ª≠ l√Ω t·ª´ng s·∫£n ph·∫©m l·∫•y v·ªÅ
                count = 0
                for item in items:
                    # -- MAPPING D·ªÆ LI·ªÜU --
                    # Chuy·ªÉn t·ª´ JSON Tiki -> Schema chung c·ªßa nh√≥m
                    
                    # L·∫•y gi√° g·ªëc (n·∫øu kh√¥ng c√≥ th√¨ l·∫•y gi√° th∆∞·ªùng)
                    original_price = item.get('list_price')
                    if not original_price:
                        original_price = item.get('price')

                    product = ProductItem(
                        id=f"tiki_{item.get('id')}",          # Th√™m prefix tiki_
                        platform="tiki",
                        title=item.get('name', ''),
                        price=item.get('price', 0),
                        original_price=original_price,
                        url=f"https://tiki.vn/{item.get('url_path', '')}",
                        image_url=item.get('thumbnail_url', ''),
                        category=category_name,               # G√°n t√™n category m√¨nh ƒëang ch·∫°y
                        brand=item.get('brand_name', 'No Brand')
                    )
                    
                    # 3. Ghi v√†o file
                    f.write(product.to_json_line() + "\n")
                    count += 1
                
                print(f"      -> ƒê√£ l∆∞u {count} s·∫£n ph·∫©m.")
                
                # 4. Ng·ªß m·ªôt ch√∫t ƒë·ªÉ kh√¥ng b·ªã ch·∫∑n IP (Quan tr·ªçng!)
                sleep_time = random.uniform(1, 3) # Ng·ªß ng·∫´u nhi√™n t·ª´ 1 ƒë·∫øn 3 gi√¢y
                time.sleep(sleep_time)
                
            except Exception as e:
                print(f"‚ùå L·ªói Exception: {e}")
                time.sleep(5)

    print(f"‚úÖ Ho√†n th√†nh crawl {category_name}. File l∆∞u t·∫°i: {output_file}")

# --- MAIN RUN ---
if __name__ == "__main__":
    # V√≠ d·ª•: Crawl 2 danh m·ª•c (B·∫°n h√£y ƒë·ªïi ID n√†y theo ph√¢n c√¥ng)
    
    # C√°ch l·∫•y ID: V√†o tiki.vn -> B·∫•m danh m·ª•c -> Nh√¨n URL
    # VD: https://tiki.vn/dien-thoai-may-tinh-bang/c1789 -> ID l√† 1789
    
    # Danh m·ª•c 1: ƒêi·ªán tho·∫°i (ID: 1789) - Ch·∫°y th·ª≠ 2 trang
    crawl_tiki_category(category_name="DienThoai", category_id=1789, max_pages=2)
    
    # Danh m·ª•c 2: Laptop (ID: 8095) - Ch·∫°y th·ª≠ 2 trang
    crawl_tiki_category(category_name="Laptop", category_id=8095, max_pages=2)

```

### 3. H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng & Ph√¢n c√¥ng

B·∫°n h√£y copy code tr√™n, g·ª≠i cho 2 b·∫°n c√≤n l·∫°i v√† d·∫∑n d√≤ nh∆∞ sau:

#### B∆∞·ªõc 1: C√†i th∆∞ vi·ªán

M·ªü Terminal/CMD v√† ch·∫°y:

```bash
pip install requests

```

#### B∆∞·ªõc 2: S·ª≠a Code cho t·ª´ng ng∆∞·ªùi (QUAN TR·ªåNG)

M·ªói ng∆∞·ªùi m·ªü file `crawler_main.py` l√™n, k√©o xu·ªëng d∆∞·ªõi c√πng ph·∫ßn `if __name__ == "__main__":` v√† s·ª≠a l·∫°i ID danh m·ª•c theo ph√¢n c√¥ng.

* **√îng A (ƒêi·ªán t·ª≠):**
```python
crawl_tiki_category("DienThoai", 1789, max_pages=100) # 100 trang ~ 4000 sp
crawl_tiki_category("MayAnh", 1801, max_pages=100)

```


* **√îng B (Th·ªùi trang):**
```python
crawl_tiki_category("ThoiTrangNu", 931, max_pages=100)
crawl_tiki_category("ThoiTrangNam", 915, max_pages=100)

```



#### B∆∞·ªõc 3: Ch·∫°y Code

G√µ l·ªánh:

```bash
python crawler_main.py

```

Ng·ªìi ƒë·ª£i n√≥ ch·∫°y. N·∫øu th·∫•y d√≤ng `-> ƒê√£ l∆∞u 40 s·∫£n ph·∫©m` hi·ªán ra li√™n t·ª•c l√† th√†nh c√¥ng. File d·ªØ li·ªáu s·∫Ω n·∫±m trong th∆∞ m·ª•c `data/`.

### 4. C√≤n Shopee th√¨ sao?

Shopee kh√≥ h∆°n v√¨ c·∫ßn l·∫•y `match_id` v√† API thay ƒë·ªïi th∆∞·ªùng xuy√™n.
N·∫øu b·∫°n ch·∫°y ·ªïn Tiki r·ªìi, t√¥i s·∫Ω g·ª≠i ti·∫øp ƒëo·∫°n function `crawl_shopee_category` ƒë·ªÉ b·∫°n gh√©p v√†o file n√†y. B·∫°n c√≥ mu·ªën l·∫•y code Shopee lu√¥n b√¢y gi·ªù kh√¥ng (n√≥ h∆°i ph·ª©c t·∫°p h∆°n ch√∫t)?
C√¢u tr·∫£ l·ªùi l√†: **CH∆ØA ƒê·ª¶ V√Ä S·∫º B·ªä L·ªñI NGAY L·∫¨P T·ª®C.**

L√Ω do l√† file `schema_shared.py` b·∫°n v·ª´a g·ª≠i l√™n l√† b·∫£n **s∆° khai (b·ªã thi·∫øu)**, trong khi file `crawl.py` l·∫°i vi·∫øt code d·ª±a tr√™n b·∫£n **ho√†n ch·ªânh**. Hai file n√†y ƒëang "l·ªách pha" nhau.

C·ª• th·ªÉ, n·∫øu b·∫°n ch·∫°y l·ªánh `python crawl.py` v·ªõi 2 file n√†y, b·∫°n s·∫Ω g·∫∑p l·ªói sau:

1. **L·ªói `TypeError`:**
* Trong `crawl.py`: B·∫°n truy·ªÅn v√†o r·∫•t nhi·ªÅu tham s·ªë: `url`, `image_url`, `category`, `brand`...
* Trong `schema_shared.py`: H√†m `__init__` ch·ªâ nh·∫≠n ƒë√∫ng 4 tham s·ªë (`id`, `platform`, `title`, `price`).
* -> **K·∫øt qu·∫£:** Code s·∫≠p v√¨ th·ª´a tham s·ªë ƒë·∫ßu v√†o.


2. **L·ªói `AttributeError`:**
* Trong `crawl.py`: B·∫°n g·ªçi h√†m `.to_json_line()` (ƒë·ªÉ ghi file JSONL).
* Trong `schema_shared.py`: Ch·ªâ c√≥ h√†m `.to_json()`.
* -> **K·∫øt qu·∫£:** Code s·∫≠p v√¨ kh√¥ng t√¨m th·∫•y h√†m.



---

### C√ÅCH KH·∫ÆC PH·ª§C (L√†m ngay ƒë·ªÉ ch·∫°y ƒë∆∞·ª£c)

B·∫°n gi·ªØ nguy√™n file `crawl.py`, nh∆∞ng **PH·∫¢I thay ƒë·ªïi to√†n b·ªô n·ªôi dung file `schema_shared.py**` b·∫±ng ƒëo·∫°n code d∆∞·ªõi ƒë√¢y (ƒë√¢y l√† b·∫£n kh·ªõp l·ªánh ho√†n to√†n v·ªõi file crawl c·ªßa b·∫°n):

#### N·ªôi dung m·ªõi cho file `schema_shared.py`

```python
import json
import time

# --- ƒê·ªäNH NGHƒ®A T√äN TR∆Ø·ªúNG (CONSTANTS) ---
FIELD_ID = "id"
FIELD_PLATFORM = "platform"
FIELD_TITLE = "title"
FIELD_URL = "url"
FIELD_IMAGE_URL = "image_url"
FIELD_PRICE = "price"
FIELD_ORIGINAL_PRICE = "original_price"
FIELD_CATEGORY = "category"
FIELD_BRAND = "brand"
FIELD_CRAWLED_AT = "crawled_at"

class ProductItem:
    def __init__(self, 
                 id: str, 
                 platform: str, 
                 title: str, 
                 price: int, 
                 url: str, 
                 image_url: str, 
                 category: str, 
                 brand: str = "No Brand",
                 original_price: int = None):
        
        # 1. X·ª≠ l√Ω logic an to√†n d·ªØ li·ªáu
        if original_price is None:
            original_price = price
            
        # X·ª≠ l√Ω Title: X√≥a k√Ω t·ª± xu·ªëng d√≤ng (\n)
        clean_title = title.strip().replace('\n', ' ').replace('\r', '') if title else ""
        
        # 2. ƒê√≥ng g√≥i v√†o dictionary
        self.data = {
            FIELD_ID: str(id),
            FIELD_PLATFORM: str(platform),
            FIELD_TITLE: clean_title,
            FIELD_PRICE: int(price),
            FIELD_ORIGINAL_PRICE: int(original_price),
            FIELD_URL: str(url),
            FIELD_IMAGE_URL: str(image_url),
            FIELD_CATEGORY: str(category),
            FIELD_BRAND: str(brand),
            FIELD_CRAWLED_AT: int(time.time())
        }

    def to_json_line(self):
        """Chuy·ªÉn object th√†nh chu·ªói JSON tr√™n 1 d√≤ng"""
        return json.dumps(self.data, ensure_ascii=False)

```

Sau khi s·ª≠a file `schema_shared.py` xong, b·∫°n ch·∫°y `python crawl.py` l√† s·∫Ω th√†nh c√¥ng!
T√¥i kh√¥ng th·ªÉ tr·ª±c ti·∫øp ch·∫°y l·ªánh crawl k·∫øt n·ªëi ƒë·∫øn server c·ªßa Tiki (v√¨ l√Ω do b·∫£o m·∫≠t, m√¥i tr∆∞·ªùng th·ª±c thi code c·ªßa t√¥i kh√¥ng c√≥ k·∫øt n·ªëi Internet ra ngo√†i).

Tuy nhi√™n, t√¥i ƒë√£ **ki·ªÉm tra logic m√£ ngu·ªìn (Code Review)** v√† ch·∫°y th·ª≠ ph·∫ßn **x·ª≠ l√Ω d·ªØ li·ªáu (Data Processing)** b·∫±ng tr√¨nh m√¥ ph·ªèng b√™n d∆∞·ªõi.

### 1. K·∫øt qu·∫£ ki·ªÉm tra

Hai file b·∫°n g·ª≠i (`# schema_shared.py` v√† `crawl.py`) ƒë√£ **HO√ÄN TO√ÄN KH·ªöP NHAU**.

* File `crawl.py` ƒë√£ g·ªçi ƒë√∫ng c√°c tham s·ªë (`id`, `platform`, `url`, `image_url`...) m√† `schema_shared.py` y√™u c·∫ßu.
* L·ªói thi·∫øu tr∆∞·ªùng d·ªØ li·ªáu ho·∫∑c sai t√™n h√†m ƒë√£ ƒë∆∞·ª£c kh·∫Øc ph·ª•c tri·ªát ƒë·ªÉ.

### 2. M√¥ ph·ªèng d·ªØ li·ªáu ƒë·∫ßu ra (Demo Output)

D∆∞·ªõi ƒë√¢y l√† k·∫øt qu·∫£ ch√≠nh x√°c m√† file `crawl.py` s·∫Ω t·∫°o ra khi ch·∫°y tr√™n m√°y b·∫°n. T√¥i ƒë√£ gi·∫£ l·∫≠p m·ªôt s·∫£n ph·∫©m l·∫•y t·ª´ Tiki ƒë·ªÉ b·∫°n xem c·∫•u tr√∫c file JSONL ƒë∆∞·ª£c ghi ra nh∆∞ th·∫ø n√†o:

```json
{"id": "tiki_123456", "platform": "tiki", "title": "iPhone 15 Pro Max 256GB - H√†ng Ch√≠nh H√£ng", "price": 28990000, "original_price": 34990000, "url": "https://tiki.vn/iphone-15-pro-max-p123456.html", "image_url": "https://tiki.vn/img/iphone15.jpg", "category": "DienThoai", "brand": "Apple", "crawled_at": 1736653066}

```

### 3. H∆∞·ªõng d·∫´n ch·∫°y ngay tr√™n m√°y b·∫°n

B√¢y gi·ªù b·∫°n c√≥ th·ªÉ t·ª± tin ch·∫°y code n√†y. H√£y l√†m theo 3 b∆∞·ªõc sau:

**B∆∞·ªõc 1: C√†i ƒë·∫∑t th∆∞ vi·ªán (n·∫øu ch∆∞a c√≥)**
M·ªü Terminal (ho·∫∑c CMD) v√† g√µ:

```bash
pip install requests

```

**B∆∞·ªõc 2: S·∫Øp x·∫øp file**
ƒê·∫£m b·∫£o th∆∞ m·ª•c c·ªßa b·∫°n c√≥ ƒë√∫ng 2 file n√†y n·∫±m c·∫°nh nhau:

* `schema_shared.py` (L∆∞u √Ω: T√™n file b·∫°n g·ª≠i ƒëang c√≥ d·∫•u `#` ·ªü ƒë·∫ßu v√† kho·∫£ng tr·∫Øng, h√£y ƒë·ªïi t√™n ch√≠nh x√°c th√†nh **`schema_shared.py`** ƒë·ªÉ file crawl import ƒë∆∞·ª£c).
* `crawl.py`

**B∆∞·ªõc 3: Ch·∫°y l·ªánh**

```bash
python crawl.py

```

Khi ch·∫°y, b·∫°n s·∫Ω th·∫•y m√†n h√¨nh hi·ªán ra nh∆∞ sau:

```text
üöÄ B·∫Øt ƒë·∫ßu crawl Tiki: DienThoai (ID: 1789)
   ... ƒêang t·∫£i trang 1/2
      -> ƒê√£ l∆∞u 40 s·∫£n ph·∫©m.
   ... ƒêang t·∫£i trang 2/2
      -> ƒê√£ l∆∞u 40 s·∫£n ph·∫©m.
‚úÖ Ho√†n th√†nh crawl DienThoai. File l∆∞u t·∫°i: data\tiki_DienThoai.jsonl
...

```

B·∫°n ki·ªÉm tra th∆∞ m·ª•c `data` s·∫Ω th·∫•y file k·∫øt qu·∫£. Code n√†y ƒë√£ **s·∫µn s√†ng s·ª≠ d·ª•ng 100%**.
ƒê·ª´ng lo, l·∫•y Cookie Shopee ƒë√¥i khi r·∫•t kh√≥ ch·ªãu v√¨ d√≤ng ƒë√≥ qu√° d√†i v√† giao di·ªán F12 r·ªëi r·∫Øm.

M√¨nh s·∫Ω ch·ªâ b·∫°n **2 "M·∫πo" c·ª±c d·ªÖ** ƒë·ªÉ l·∫•y ƒë∆∞·ª£c n√≥ m√† kh√¥ng c·∫ßn m√≤ m·∫´m th·ªß c√¥ng. H√£y th·ª≠ **C√°ch 1** tr∆∞·ªõc (d·ªÖ nh·∫•t).

---

### C√ÅCH 1: COPY TO√ÄN B·ªò HEADER (Kh√¥ng c·∫ßn t√¨m d√≤ng Cookie)

Thay v√¨ ƒëi t√¨m d√≤ng ch·ªØ `Cookie` b√© t√≠, b·∫°n h√£y copy **to√†n b·ªô** nh·ªØng g√¨ tr√¨nh duy·ªát g·ª≠i ƒëi, d√°n v√†o Notepad r·ªìi l·ªçc sau.

1. **B∆∞·ªõc 1:** M·ªü trang danh m·ª•c Shopee (v√≠ d·ª•: t√¨m "√°o thun").
2. **B∆∞·ªõc 2:** B·∫•m **F12**, ch·ªçn tab **Network**.
3. **B∆∞·ªõc 3:** (Quan tr·ªçng) B·∫•m ph√≠m **F5** ƒë·ªÉ t·∫£i l·∫°i trang. L√∫c n√†y danh s√°ch b√™n d∆∞·ªõi s·∫Ω ch·∫°y ·∫ßm ·∫ßm.
4. **B∆∞·ªõc 4:** ·ªû √¥ l·ªçc (Filter) g√≥c tr√™n b√™n tr√°i c·ªßa b·∫£ng Network, g√µ ch·ªØ: `search_items`.
* B·∫°n s·∫Ω th·∫•y ch·ªâ c√≤n l·∫°i 1 ho·∫∑c 2 d√≤ng.


5. **B∆∞·ªõc 5:** B·∫•m **Chu·ªôt ph·∫£i** v√†o d√≤ng `search_items...` ƒë√≥.
* Ch·ªçn **Copy** > **Copy Request Headers**.


6. **B∆∞·ªõc 6:** M·ªü **Notepad** (ho·∫∑c tr√¨nh so·∫°n th·∫£o text b·∫•t k·ª≥), b·∫•m **Paste (Ctrl+V)**.
7. **B∆∞·ªõc 7:** T√¨m d√≤ng b·∫Øt ƒë·∫ßu b·∫±ng ch·ªØ `Cookie:` (th∆∞·ªùng n√≥ n·∫±m ·ªü gi·ªØa ho·∫∑c cu·ªëi).
* Copy to√†n b·ªô n·ªôi dung **SAU** d·∫•u hai ch·∫•m `:`. (L∆∞u √Ω: N√≥ r·∫•t d√†i, c√≥ khi d√†i 3-4 d√≤ng m√†n h√¨nh, h√£y ch·∫Øc ch·∫Øn copy h·∫øt ƒë·∫øn khi g·∫∑p d·∫•u xu·ªëng d√≤ng).



---

### C√ÅCH 2: "TR√ôM CU·ªêI" - D√ôNG WEBSITE CHUY·ªÇN ƒê·ªîI (Ch·∫Øc ƒÉn 100%)

N·∫øu c√°ch 1 b·∫°n copy b·ªã thi·∫øu ho·∫∑c sai ƒë·ªãnh d·∫°ng, h√£y d√πng c√°ch n√†y. C√°ch n√†y bi·∫øn l·ªánh c·ªßa tr√¨nh duy·ªát th√†nh code Python lu√¥n, kh√¥ng tr∆∞·ª£t ƒëi ƒë√¢u ƒë∆∞·ª£c.

1. L√†m l·∫°i B∆∞·ªõc 1 ƒë·∫øn B∆∞·ªõc 4 gi·ªëng h·ªát ·ªü tr√™n (F12 > Network > Filter `search_items`).
2. **B∆∞·ªõc 5 (Kh√°c bi·ªát):** Chu·ªôt ph·∫£i v√†o d√≤ng ƒë√≥ > Ch·ªçn **Copy** > Ch·ªçn **Copy as cURL (bash)**.
* *L∆∞u √Ω: Ch·ªçn ƒë√∫ng d√≤ng `Copy as cURL (bash)`, ƒë·ª´ng ch·ªçn cmd hay powershell.*


3. **B∆∞·ªõc 6:** V√†o trang web: **[curlconverter.com](https://curlconverter.com/)**
4. **B∆∞·ªõc 7:** D√°n (Ctrl+V) v√†o √¥ "curl command" ·ªü tr√™n c√πng.
5. **B∆∞·ªõc 8:** Nh√¨n xu·ªëng d∆∞·ªõi, web s·∫Ω t·ª± sinh ra code Python.
* B·∫°n t√¨m bi·∫øn `cookies = { ... }` ho·∫∑c `headers = { ... }`.
* Copy ƒë√∫ng c√°i chu·ªói d√†i ngo·∫±ng trong ph·∫ßn `'Cookie': '...'` ƒë√≥.
DATE 21/1/2026
C√¢u tr·∫£ l·ªùi l√†: **KH√îNG**.

V·ªõi ƒëo·∫°n code hi·ªán t·∫°i, m·ªói l·∫ßn b·∫°n ch·∫°y l·∫°i file script n√†y, **d·ªØ li·ªáu c≈© s·∫Ω b·ªã x√≥a s·∫°ch ho√†n to√†n** v√† thay th·∫ø b·∫±ng d·ªØ li·ªáu m·ªõi.

**L√Ω do n·∫±m ·ªü ƒëo·∫°n cu·ªëi c·ªßa code (d√≤ng 82-83):**

```python
if __name__ == "__main__":
    if os.path.exists(OUTPUT_FILE):
        os.remove(OUTPUT_FILE)  # <--- D√≤ng n√†y l·ªánh cho m√°y t√≠nh X√ìA file c≈© n·∫øu n√≥ t·ªìn t·∫°i

```

### C√°ch ho·∫°t ƒë·ªông c·ª• th·ªÉ c·ªßa code b·∫°n:

1. **B∆∞·ªõc 1:** Khi b·∫°n b·∫•m ch·∫°y, code ki·ªÉm tra xem file `data/tiki_all.jsonl` c√≥ t·ªìn t·∫°i kh√¥ng.
2. **B∆∞·ªõc 2:** N·∫øu c√≥, n√≥ **x√≥a vƒ©nh vi·ªÖn** file ƒë√≥ (`os.remove`).
3. **B∆∞·ªõc 3:** Sau ƒë√≥ n√≥ m·ªõi b·∫Øt ƒë·∫ßu crawl v√† t·∫°o file m·ªõi tinh ƒë·ªÉ ghi d·ªØ li·ªáu v√†o.

---

### üí° N·∫øu b·∫°n mu·ªën GI·ªÆ L·∫†I data c≈© v√† ch·ªâ n·ªëi th√™m data m·ªõi v√†o:

B·∫°n c·∫ßn **x√≥a ho·∫∑c comment (v√¥ hi·ªáu h√≥a)** d√≤ng code x√≥a file ƒëi. H√£y s·ª≠a ƒëo·∫°n cu·ªëi th√†nh nh∆∞ sau:

```python
# ================== MAIN ==================
if __name__ == "__main__":
    # if os.path.exists(OUTPUT_FILE):  <-- Th√™m d·∫•u # ·ªü ƒë·∫ßu ƒë·ªÉ v√¥ hi·ªáu h√≥a
    #     os.remove(OUTPUT_FILE)       <-- Th√™m d·∫•u # ·ªü ƒë·∫ßu ƒë·ªÉ v√¥ hi·ªáu h√≥a

    for cat in TIKI_CATEGORIES:
        crawl_tiki_category(cat["name"], cat["id"], max_pages=100)
    
    # ... (ph·∫ßn c√≤n l·∫°i gi·ªØ nguy√™n)

```

Khi ƒë√≥, ch·∫ø ƒë·ªô m·ªü file `mode="a"` (append) ·ªü trong h√†m `crawl_tiki_category` s·∫Ω ph√°t huy t√°c d·ª•ng l√† n·ªëi ti·∫øp d·ªØ li·ªáu m·ªõi v√†o ƒëu√¥i file c≈© thay v√¨ x√≥a ƒëi.
ƒê·ªÉ l√†m ƒë∆∞·ª£c vi·ªác n√†y (l·∫ßn 1 crawl 10.000, l·∫ßn 2 crawl ti·∫øp 10.000 -> file c√≥ 20.000), b·∫°n c·∫ßn thay ƒë·ªïi 2 logic quan tr·ªçng trong code:

1. **Kh√¥ng x√≥a file c≈©:** B·ªè ƒëo·∫°n l·ªánh `os.remove`.
2. **ƒê·ªçc l·∫°i d·ªØ li·ªáu c≈© tr∆∞·ªõc khi ch·∫°y:** ƒê·ªÉ tr√°nh vi·ªác l·∫ßn 2 crawl l·∫°i d√≠nh nh·ªØng s·∫£n ph·∫©m ƒë√£ c√≥ ·ªü l·∫ßn 1 (tr√°nh tr√πng l·∫∑p), b·∫°n c·∫ßn load c√°c ID ƒë√£ c√≥ v√†o bi·∫øn `SEEN`.

D∆∞·ªõi ƒë√¢y l√† ƒëo·∫°n code ƒë√£ ƒë∆∞·ª£c s·ª≠a ƒë·ªïi t·ªëi ∆∞u cho vi·ªác **c·∫≠p nh·∫≠t/n·ªëi ti·∫øp d·ªØ li·ªáu**:

### Code s·ª≠a ƒë·ªïi

```python
import requests
import time
import random
import os
import json  # C·∫ßn th√™m th∆∞ vi·ªán json ƒë·ªÉ ƒë·ªçc file c≈©
from schema_shared import ProductItem

print("üìÇ CWD =", os.getcwd())

# ================== CONFIG ==================
DATA_FOLDER = "data"
os.makedirs(DATA_FOLDER, exist_ok=True)

OUTPUT_FILE = os.path.join(DATA_FOLDER, "tiki_all.jsonl")

HEADERS = {
    "User-Agent": (
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
        "AppleWebKit/537.36 (KHTML, like Gecko) "
        "Chrome/120.0.0.0 Safari/537.36"
    ),
    "Accept": "application/json, text/plain, */*",
    "Accept-Language": "vi-VN,vi;q=0.9",
    "Referer": "https://tiki.vn/",
}

SESSION = requests.Session()
SESSION.headers.update(HEADERS)

SEEN = set()

# === [M·ªöI] H√ÄM ƒê·ªåC D·ªÆ LI·ªÜU C≈® ƒê·ªÇ TR√ÅNH TR√ôNG L·∫∂P ===
def load_existing_data():
    if not os.path.exists(OUTPUT_FILE):
        return
    
    print(f"üîÑ ƒêang ƒë·ªçc d·ªØ li·ªáu c≈© t·ª´ {OUTPUT_FILE}...")
    count = 0
    try:
        with open(OUTPUT_FILE, "r", encoding="utf-8") as f:
            for line in f:
                try:
                    data = json.loads(line)
                    # Gi·∫£ s·ª≠ id trong file jsonl l√† "tiki_12345" ho·∫∑c field id
                    if "id" in data:
                        SEEN.add(data["id"])
                        count += 1
                except:
                    continue
    except Exception as e:
        print(f"‚ö†Ô∏è L·ªói ƒë·ªçc file c≈©: {e}")
    
    print(f"‚úÖ ƒê√£ t·∫£i {count} s·∫£n ph·∫©m c≈© v√†o b·ªô nh·ªõ (SEEN).")

# ================== CRAWL 1 CATEGORY ==================
def crawl_tiki_category(name, cid, max_pages=50):
    print(f"\nüöÄ [TIKI] START {name} ({cid})")

    for page in range(1, max_pages + 1):
        print(f"[{name}] Page {page}/{max_pages}")

        url = (
            "https://tiki.vn/api/personalish/v1/blocks/listings"
            f"?limit=40&include=advertisement"
            f"&aggregations=2&version=home-persionalized"
            f"&trackity_id=123&category={cid}&page={page}"
        )

        try:
            resp = SESSION.get(url, timeout=20)
            if resp.status_code != 200:
                print("‚ö†Ô∏è HTTP", resp.status_code)
                break

            items = resp.json().get("data", [])
            if not items:
                break

            # M·ªü file mode 'a' (append) ƒë·ªÉ ghi n·ªëi ti·∫øp
            with open(OUTPUT_FILE, "a", encoding="utf-8") as f:
                new_items_count = 0
                for item in items:
                    pid = f"tiki_{item.get('id')}"
                    
                    # QUAN TR·ªåNG: Ki·ªÉm tra xem ƒë√£ c√≥ trong l·∫ßn crawl tr∆∞·ªõc ch∆∞a
                    if pid in SEEN:
                        continue
                    
                    SEEN.add(pid) # ƒê√°nh d·∫•u l√† ƒë√£ th·∫•y

                    original_price = item.get("list_price") or item.get("price")

                    product = ProductItem(
                        id=pid,
                        platform="tiki",
                        title=item.get("name", ""),
                        price=int(item.get("price", 0)),
                        original_price=int(original_price or 0),
                        url="https://tiki.vn/" + item.get("url_path", ""),
                        image_url=item.get("thumbnail_url", ""),
                        category=name,
                        brand=item.get("brand_name", "No Brand"),
                    )

                    f.write(product.to_json_line() + "\n")
                    new_items_count += 1
                
                if new_items_count > 0:
                    print(f"   -> ƒê√£ ghi th√™m {new_items_count} s·∫£n ph·∫©m m·ªõi.")

            time.sleep(random.uniform(1, 2))

        except Exception as e:
            print("‚ùå Error:", e)
            time.sleep(3)

    print(f"‚úÖ [TIKI] FINISH {name}")

# ================== CATEGORY LIST ==================
TIKI_CATEGORIES = [
    {"name": "dua-muong-nia", "id": 3179},
    # Th√™m c√°c category kh√°c...
]

# ================== MAIN ==================
if __name__ == "__main__":
    # 1. KH√îNG X√ìA FILE C≈® (ƒê√£ b·ªè d√≤ng os.remove)
    
    # 2. Load d·ªØ li·ªáu c≈© l√™n RAM ƒë·ªÉ check tr√πng
    load_existing_data()

    # 3. Ch·∫°y crawl
    for cat in TIKI_CATEGORIES:
        crawl_tiki_category(cat["name"], cat["id"], max_pages=100)

    print("\nüéâ DONE ‚Äì TIKI UPDATE COMPLETED")
    print("üì¶ Total unique items in SEEN:", len(SEEN))

```

### Gi·∫£i th√≠ch c√°c thay ƒë·ªïi:

1. **Gi·ªØ nguy√™n ƒë·ªãnh d·∫°ng `.jsonl`:**
* ƒê√¢y l√† ƒë·ªãnh d·∫°ng t·ªët nh·∫•t cho Big Data v√† Scraping.
* N·∫øu b·∫°n d√πng `.json` th∆∞·ªùng (d·∫°ng danh s√°ch `[...]`), m·ªói l·∫ßn th√™m d·ªØ li·ªáu b·∫°n ph·∫£i ƒë·ªçc to√†n b·ªô 10.000 d√≤ng c≈© l√™n, th√™m v√†o, r·ªìi ghi l·∫°i to√†n b·ªô 20.000 d√≤ng. R·∫•t n·∫∑ng m√°y v√† d·ªÖ l·ªói file.
* D√πng `.jsonl` (m·ªói d√≤ng 1 object), b·∫°n ch·ªâ vi·ªác ghi n·ªëi ti·∫øp v√†o cu·ªëi file (append), r·∫•t nhanh v√† an to√†n.


2. **H√†m `load_existing_data()`:**
* H√†m n√†y ch·∫°y ƒë·∫ßu ti√™n. N√≥ m·ªü file `tiki_all.jsonl` hi·ªán c√≥, ƒë·ªçc h·∫øt c√°c ID s·∫£n ph·∫©m v√† l∆∞u v√†o t·∫≠p h·ª£p `SEEN`.
* V√≠ d·ª•: File c≈© c√≥ s·∫£n ph·∫©m A, B. Khi ch·∫°y l·∫ßn 2, code bi·∫øt A v√† B ƒë√£ t·ªìn t·∫°i.


3. **Check tr√πng l·∫∑p (`if pid in SEEN: continue`):**
* Khi crawl trang m·ªõi, n·∫øu g·∫∑p l·∫°i s·∫£n ph·∫©m A, code s·∫Ω b·ªè qua, kh√¥ng ghi v√†o file n·ªØa. File c·ªßa b·∫°n s·∫Ω ch·ªâ ch·ª©a c√°c s·∫£n ph·∫©m duy nh·∫•t (Unique).



**K·∫øt qu·∫£:**

* Ch·∫°y l·∫ßn 1: File c√≥ 10.000 d√≤ng.
* Ch·∫°y l·∫ßn 2 (c√≥ th·ªÉ crawl category kh√°c, ho·∫∑c crawl th√™m trang m·ªõi): File s·∫Ω n·ªëi th√™m d·ªØ li·ªáu th√†nh 20.000 d√≤ng. C√°c s·∫£n ph·∫©m c≈© v·∫´n ƒë∆∞·ª£c gi·ªØ nguy√™n.
* D∆∞·ªõi ƒë√¢y l√† gi·∫£i th√≠ch chi ti·∫øt v·ªÅ c∆° ch·∫ø ho·∫°t ƒë·ªông c·ªßa ƒëo·∫°n code m·ªõi (phi√™n b·∫£n c·∫≠p nh·∫≠t d·ªØ li·ªáu) v√† chi·∫øn thu·∫≠t crawl m√† code n√†y ƒëang s·ª≠ d·ª•ng.

### 1. T∆∞ duy c·ªët l√µi: "Kh√¥ng qu√™n qu√° kh·ª©"

Kh√°c v·ªõi code c≈© (x√≥a ƒëi l√†m l·∫°i), code m·ªõi ho·∫°t ƒë·ªông theo nguy√™n t·∫Øc **t√≠ch l≈©y**. N√≥ gi·ªëng nh∆∞ vi·ªác b·∫°n vi·∫øt nh·∫≠t k√Ω: ng√†y h√¥m nay vi·∫øt ti·∫øp v√†o trang sau c·ªßa ng√†y h√¥m qua, ch·ª© kh√¥ng x√© b·ªè cu·ªën s·ªï ƒëi.

Quy tr√¨nh x·ª≠ l√Ω g·ªìm 3 b∆∞·ªõc ch√≠nh:

1. **Nh·ªõ l·∫°i (Load):** Xem m√¨nh ƒë√£ c√≥ g√¨ r·ªìi.
2. **L·ªçc (Filter):** Khi ƒëi l·∫•y c√°i m·ªõi, n·∫øu th·∫•y c√°i ƒë√£ c√≥ r·ªìi th√¨ b·ªè qua.
3. **Ghi ti·∫øp (Append):** Ch·ªâ ghi nh·ªØng c√°i th·ª±c s·ª± m·ªõi v√†o cu·ªëi file.

---

### 2. Gi·∫£i th√≠ch chi ti·∫øt t·ª´ng ph·∫ßn code

#### A. H√†m `load_existing_data()` - "Ki·ªÉm h√†ng t·ªìn kho"

ƒê√¢y l√† ph·∫ßn quan tr·ªçng nh·∫•t ƒë∆∞·ª£c th√™m v√†o.

```python
def load_existing_data():
    # ... (code m·ªü file)
    with open(OUTPUT_FILE, "r", encoding="utf-8") as f:
        for line in f:
            data = json.loads(line)
            if "id" in data:
                SEEN.add(data["id"]) # <--- M·∫§U CH·ªêT

```

* **M·ª•c ƒë√≠ch:** Tr∆∞·ªõc khi b·∫Øt ƒë·∫ßu crawl, m√°y t√≠nh m·ªü file `tiki_all.jsonl` ra ƒë·ªçc m·ªôt l∆∞·ª£t.
* **Bi·∫øn `SEEN`:** L√† m·ªôt t·∫≠p h·ª£p (`set`) ch·ª©a c√°c ID s·∫£n ph·∫©m (v√≠ d·ª•: `tiki_123`, `tiki_456`).
* **T√°c d·ª•ng:** Gi√∫p ch∆∞∆°ng tr√¨nh "bi·∫øt" l√† s·∫£n ph·∫©m n√†o ƒë√£ n·∫±m trong file r·ªìi ƒë·ªÉ l√°t n·ªØa kh√¥ng c√†o l·∫°i n·ªØa.

#### B. Ch·∫ø ƒë·ªô m·ªü file `mode="a"` - "Vi·∫øt n·ªëi ƒëu√¥i"

Trong h√†m `crawl_tiki_category`:

```python
with open(OUTPUT_FILE, "a", encoding="utf-8") as f:

```

* **`"w"` (Write - c≈©):** M·ªü file ra, x√≥a tr·∫Øng m·ªçi th·ª© b√™n trong, vi·∫øt t·ª´ ƒë·∫ßu.
* **`"a"` (Append - m·ªõi):** M·ªü file ra, con tr·ªè chu·ªôt nh·∫£y xu·ªëng **d√≤ng cu·ªëi c√πng**, vi·∫øt ti·∫øp d·ªØ li·ªáu m·ªõi v√†o ƒë√≥. D·ªØ li·ªáu c≈© v·∫´n an to√†n.

#### C. Logic l·ªçc tr√πng l·∫∑p

```python
pid = f"tiki_{item.get('id')}"

if pid in SEEN:  # <--- H√ÄNG R√ÄO B·∫¢O V·ªÜ
    continue     # N·∫øu ƒë√£ th·∫•y ID n√†y r·ªìi th√¨ b·ªè qua ngay, kh√¥ng l√†m g√¨ c·∫£
    
SEEN.add(pid)    # N·∫øu ch∆∞a th·∫•y, th√™m v√†o danh s√°ch ƒë√£ th·∫•y
# ... sau ƒë√≥ m·ªõi ghi v√†o file

```

* ƒêo·∫°n n√†y ƒë·∫£m b·∫£o d√π b·∫°n ch·∫°y code 100 l·∫ßn, file k·∫øt qu·∫£ c≈©ng kh√¥ng bao gi·ªù c√≥ 2 d√≤ng ch·ª©a c√πng 1 s·∫£n ph·∫©m.

---

### 3. Chi·∫øn thu·∫≠t Crawl (C√°ch l·∫•y d·ªØ li·ªáu)

Code n√†y s·ª≠ d·ª•ng ph∆∞∆°ng ph√°p **API Crawling** (gi·∫£ l·∫≠p request API), ch·ª© kh√¥ng ph·∫£i HTML Parsing (nh∆∞ d√πng BeautifulSoup).

* **API Endpoint:**
`https://tiki.vn/api/personalish/v1/blocks/listings...`
* **C√°ch ho·∫°t ƒë·ªông:**
1. Khi b·∫°n l∆∞·ªõt web Tiki, tr√¨nh duy·ªát √¢m th·∫ßm g·ª≠i y√™u c·∫ßu ƒë·∫øn m√°y ch·ªß Tiki ƒë·ªÉ l·∫•y danh s√°ch s·∫£n ph·∫©m.
2. M√°y ch·ªß Tiki tr·∫£ v·ªÅ d·ªØ li·ªáu d·∫°ng **JSON** (ch·ªØ th√¥, c√≥ c·∫•u tr√∫c), kh√¥ng ph·∫£i giao di·ªán h√¨nh ·∫£nh.
3. Code c·ªßa b·∫°n gi·∫£ v·ªù l√†m tr√¨nh duy·ªát (nh·ªù `HEADERS` v√† `User-Agent`) ƒë·ªÉ g·ªçi ƒë√∫ng ƒë∆∞·ªùng d·∫´n ƒë√≥.


* **∆Øu ƒëi·ªÉm c·ªßa c√°ch n√†y:**
* **T·ªëc ƒë·ªô si√™u nhanh:** V√¨ kh√¥ng ph·∫£i t·∫£i h√¨nh ·∫£nh, CSS, qu·∫£ng c√°o... ch·ªâ t·∫£i d·ªØ li·ªáu ch·ªØ.
* **D·ªØ li·ªáu s·∫°ch:** L·∫•y ƒë∆∞·ª£c ch√≠nh x√°c gi√°, ID, t√™n m√† kh√¥ng c·∫ßn ph·∫£i "b·ªõi" trong ƒë·ªëng th·∫ª HTML `<div>`, `<span>` ph·ª©c t·∫°p.
* **√çt b·ªã ch·∫∑n h∆°n:** So v·ªõi vi·ªác c√†o HTML li√™n t·ª•c.



### 4. T√≥m t·∫Øt lu·ªìng ƒëi c·ªßa d·ªØ li·ªáu

1. **Kh·ªüi ƒë·ªông:** T·∫°o th∆∞ m·ª•c `data`.
2. **Check kho:** ƒê·ªçc file `tiki_all.jsonl` (n·∫øu c√≥) -> n·∫°p 10.000 ID c≈© v√†o RAM (`SEEN`).
3. **V√†o vi·ªác (V√≤ng l·∫∑p trang 1 -> 100):**
* G·ªçi API l·∫•y 40 s·∫£n ph·∫©m.
* Duy·ªát t·ª´ng s·∫£n ph·∫©m:
* S·∫£n ph·∫©m A (ID: 111): C√≥ trong `SEEN` ch∆∞a? -> **C√≥** -> B·ªè qua.
* S·∫£n ph·∫©m B (ID: 222): C√≥ trong `SEEN` ch∆∞a? -> **Ch∆∞a** -> Ghi v√†o cu·ªëi file `tiki_all.jsonl` -> Th√™m 222 v√†o `SEEN`.




4. **K·∫øt th√∫c:** File `tiki_all.jsonl` gi·ªù ch·ª©a 10.000 c≈© + c√°c s·∫£n ph·∫©m m·ªõi t√¨m ƒë∆∞·ª£c.

### 5. L∆∞u √Ω quan tr·ªçng v·ªÅ ƒë·ªãnh d·∫°ng `.jsonl`

B·∫°n ƒëang l∆∞u file d∆∞·ªõi d·∫°ng **JSON Lines** (m·ªói d√≤ng l√† m·ªôt object JSON ƒë·ªôc l·∫≠p).

* **∆Øu ƒëi·ªÉm:** C√≥ th·ªÉ ghi th√™m (append) c·ª±c d·ªÖ.
* **Nh∆∞·ª£c ƒëi·ªÉm:** Kh√¥ng th·ªÉ m·ªü tr·ª±c ti·∫øp b·∫±ng `json.load()` th√¥ng th∆∞·ªùng (s·∫Ω l·ªói), m√† ph·∫£i ƒë·ªçc t·ª´ng d√≤ng (line-by-line) nh∆∞ trong h√†m `load_existing_data` m√¨nh vi·∫øt.
* C√¢u tr·∫£ l·ªùi l√†: **C√ì, ch·∫°y nhanh h∆°n R·∫§T NHI·ªÄU.**

N·∫øu code hi·ªán t·∫°i ch·∫°y m·∫•t **10 ph√∫t**, th√¨ code ƒëa lu·ªìng (Multi-threading) c√≥ th·ªÉ ch·ªâ m·∫•t **1-2 ph√∫t**.

### T·∫°i sao l·∫°i nhanh h∆°n?

* **Code hi·ªán t·∫°i (ƒê∆°n lu·ªìng - Single Thread):** Gi·ªëng nh∆∞ 1 shipper ƒëi giao h√†ng. Giao xong ƒë∆°n 1, quay v·ªÅ kho l·∫•y ƒë∆°n 2 ƒëi giao ti·∫øp. Th·ªùi gian "ch·∫øt" l√† l√∫c ch·ªù xe ch·∫°y (ch·ªù ph·∫£n h·ªìi t·ª´ Tiki).
* **Code ƒëa lu·ªìng (Multi-threading):** Gi·ªëng nh∆∞ b·∫°n thu√™ 10 shipper. C√πng l√∫c 10 ng∆∞·ªùi ch·∫°y ƒëi l·∫•y h√†ng ·ªü 10 trang kh√°c nhau. Ai v·ªÅ tr∆∞·ªõc th√¨ ghi d·ªØ li·ªáu tr∆∞·ªõc. T·∫≠n d·ª•ng t·ªëi ƒëa th·ªùi gian ch·ªù.

---

### ‚ö†Ô∏è R·ª¶I RO L·ªöN C·∫¶N L∆ØU √ù

Tiki **r·∫•t gh√©t** vi·ªác b·ªã spam request qu√° nhanh.

* N·∫øu b·∫°n m·ªü **qu√° nhi·ªÅu lu·ªìng** (v√≠ d·ª• 50-100 lu·ªìng), Tiki s·∫Ω nghƒ© b·∫°n l√† hacker t·∫•n c√¥ng (DDOS) v√† **kh√≥a IP vƒ©nh vi·ªÖn** trong v√†i gi·ªù/ng√†y.
* **Gi·∫£i ph√°p:** Ch·ªâ n√™n d√πng kho·∫£ng **5 ƒë·∫øn 10 lu·ªìng** (workers) v√† v·∫´n ph·∫£i gi·ªØ `sleep` nh·∫π.

---

### CODE N√ÇNG C·∫§P: ƒêA LU·ªíNG + CH·ªêNG TR√ôNG + GHI FILE AN TO√ÄN

D∆∞·ªõi ƒë√¢y l√† phi√™n b·∫£n "x·ªãn" nh·∫•t, s·ª≠ d·ª•ng th∆∞ vi·ªán `concurrent.futures` ƒë·ªÉ qu·∫£n l√Ω lu·ªìng v√† `threading.Lock` ƒë·ªÉ tr√°nh l·ªói khi 2 lu·ªìng c√πng ghi v√†o 1 file.

```python
import requests
import time
import random
import os
import json
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
from schema_shared import ProductItem

print("üìÇ CWD =", os.getcwd())

# ================== CONFIG ==================
DATA_FOLDER = "data"
os.makedirs(DATA_FOLDER, exist_ok=True)
OUTPUT_FILE = os.path.join(DATA_FOLDER, "tiki_all.jsonl")

# S·ªë l∆∞·ª£ng lu·ªìng ch·∫°y song song (ƒê·ª´ng ƒë·ªÉ qu√° cao k·∫ªo b·ªã ch·∫∑n IP)
MAX_WORKERS = 5 

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Accept": "application/json, text/plain, */*",
    "Referer": "https://tiki.vn/",
}

# Kh√≥a an to√†n ƒë·ªÉ c√°c lu·ªìng kh√¥ng tranh nhau ghi file c√πng l√∫c
FILE_LOCK = threading.Lock()
SEEN_LOCK = threading.Lock()

SEEN = set()

# ================== H√ÄM H·ªñ TR·ª¢ ==================
def load_existing_data():
    if not os.path.exists(OUTPUT_FILE):
        return
    print(f"üîÑ ƒêang ƒë·ªçc d·ªØ li·ªáu c≈©...")
    count = 0
    try:
        with open(OUTPUT_FILE, "r", encoding="utf-8") as f:
            for line in f:
                try:
                    data = json.loads(line)
                    if "id" in data:
                        SEEN.add(data["id"])
                        count += 1
                except:
                    continue
    except Exception as e:
        print(f"‚ö†Ô∏è L·ªói ƒë·ªçc file: {e}")
    print(f"‚úÖ ƒê√£ t·∫£i {count} s·∫£n ph·∫©m c≈© v√†o b·ªô nh·ªõ.")

def save_items_to_file(items, category_name):
    """H√†m n√†y ƒë∆∞·ª£c b·∫£o v·ªá b·ªüi Lock, ch·ªâ 1 lu·ªìng ƒë∆∞·ª£c ghi t·∫°i 1 th·ªùi ƒëi·ªÉm"""
    new_count = 0
    
    # M·ªü file v√† ghi ngay l·∫≠p t·ª©c
    with FILE_LOCK: # <--- KH√ìA FILE
        with open(OUTPUT_FILE, "a", encoding="utf-8") as f:
            for item in items:
                pid = f"tiki_{item.get('id')}"
                
                # Ki·ªÉm tra tr√πng l·∫∑p an to√†n
                if pid in SEEN:
                    continue
                
                SEEN.add(pid) # Th√™m v√†o b·ªô nh·ªõ
                
                original_price = item.get("list_price") or item.get("price")
                product = ProductItem(
                    id=pid,
                    platform="tiki",
                    title=item.get("name", ""),
                    price=int(item.get("price", 0)),
                    original_price=int(original_price or 0),
                    url="https://tiki.vn/" + item.get("url_path", ""),
                    image_url=item.get("thumbnail_url", ""),
                    category=category_name,
                    brand=item.get("brand_name", "No Brand"),
                )
                f.write(product.to_json_line() + "\n")
                new_count += 1
                
    return new_count

# ================== CRAWL 1 TRANG (NHI·ªÜM V·ª§ C·ª¶A 1 LU·ªíNG) ==================
def crawl_single_page(category_name, category_id, page):
    # M·ªói lu·ªìng t·ª± t·∫°o session ho·∫∑c d√πng request r·ªùi ƒë·ªÉ tr√°nh xung ƒë·ªôt
    url = (
        "https://tiki.vn/api/personalish/v1/blocks/listings"
        f"?limit=40&include=advertisement"
        f"&aggregations=2&version=home-persionalized"
        f"&trackity_id=123&category={category_id}&page={page}"
    )
    
    try:
        # Gi·∫£ l·∫≠p delay ng·∫´u nhi√™n nh·ªè ƒë·ªÉ tr√°nh b·ªã server nghi ng·ªù
        time.sleep(random.uniform(0.5, 1.5))
        
        resp = requests.get(url, headers=HEADERS, timeout=20)
        if resp.status_code != 200:
            return f"‚ùå Page {page} l·ªói HTTP {resp.status_code}"
            
        items = resp.json().get("data", [])
        if not items:
            return f"‚ö†Ô∏è Page {page} kh√¥ng c√≥ d·ªØ li·ªáu (H·∫øt h√†ng?)"

        # G·ªçi h√†m l∆∞u an to√†n
        added = save_items_to_file(items, category_name)
        
        return f"‚úÖ {category_name} - Page {page}: L·∫•y {len(items)}, M·ªõi {added}"

    except Exception as e:
        return f"‚ùå L·ªói Page {page}: {e}"

# ================== MAIN ==================
TIKI_CATEGORIES = [
    {"name": "nha-sach-tiki", "id": 8322},
    {"name": "dien-thoai-may-tinh-bang", "id": 1789},
    {"name": "lam-dep-suc-khoe", "id": 1520},
    {"name": "dien-gia-dung", "id": 1882},
    {"name": "thoi-trang-nu", "id": 931}
]

if __name__ == "__main__":
    load_existing_data()
    
    # T·∫°o danh s√°ch c√°c nhi·ªám v·ª• (Tasks)
    # V√≠ d·ª•: [Cat A - Page 1, Cat A - Page 2, ..., Cat B - Page 1...]
    all_tasks = []
    MAX_PAGES = 50 # S·ªë trang mu·ªën c√†o m·ªói danh m·ª•c
    
    for cat in TIKI_CATEGORIES:
        for p in range(1, MAX_PAGES + 1):
            all_tasks.append((cat["name"], cat["id"], p))
            
    print(f"\nüöÄ B·∫ÆT ƒê·∫¶U CH·∫†Y ƒêA LU·ªíNG: {MAX_WORKERS} workers cho {len(all_tasks)} trang...")
    
    # B·∫Øt ƒë·∫ßu ch·∫°y song song
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        # G·ª≠i t·∫•t c·∫£ nhi·ªám v·ª• v√†o b·ªÉ (Pool)
        future_to_page = {
            executor.submit(crawl_single_page, t[0], t[1], t[2]): t 
            for t in all_tasks
        }
        
        # Ch·ªù v√† in k·∫øt qu·∫£ khi t·ª´ng lu·ªìng ho√†n th√†nh
        for future in as_completed(future_to_page):
            result = future.result()
            print(result)

    print("\nüéâ DONE ‚Äì TIKI MULTI-THREAD FINISHED")
    print("üì¶ Total unique items in SEEN:", len(SEEN))

```

### Gi·∫£i th√≠ch s·ª± thay ƒë·ªïi:

1. **`ThreadPoolExecutor`:** ƒê√¢y l√† "√¥ng ch·ªß" qu·∫£n l√Ω nh√¢n vi√™n. M√¨nh set `MAX_WORKERS = 5`, nghƒ©a l√† lu√¥n c√≥ 5 "nh√¢n vi√™n" l√†m vi·ªác c√πng l√∫c. Nh√¢n vi√™n 1 xong trang 1 s·∫Ω l·∫≠p t·ª©c l·∫•y trang 6 l√†m ti·∫øp, kh√¥ng ng·ªìi ch∆°i.
2. **`FILE_LOCK`:** ƒê√¢y l√† c√°i "ch√¨a kh√≥a". V√¨ 5 nh√¢n vi√™n c√πng ch·∫°y, n·∫øu 2 ng∆∞·ªùi c√πng c·∫ßm b√∫t vi·∫øt v√†o file `tiki_all.jsonl` c√πng l√∫c th√¨ file s·∫Ω l·ªói d√≤ng. Lock ƒë·∫£m b·∫£o t·∫°i 1 t√≠ch t·∫Øc, ch·ªâ 1 ng∆∞·ªùi ƒë∆∞·ª£c vi·∫øt.
3. **B·ªè v√≤ng l·∫∑p tu·∫ßn t·ª±:** Thay v√¨ `for category -> for page` (ch·∫°y h·∫øt c√°i n√†y t·ªõi c√°i kia), m√¨nh t·∫°o m·ªôt danh s√°ch `all_tasks` ch·ª©a t·∫•t c·∫£ c√°c trang c·∫ßn c√†o (v√≠ d·ª• 500 trang), r·ªìi n√©m h·∫øt v√†o m√°y x·ª≠ l√Ω song song.

**B·∫°n ch·∫°y th·ª≠ xem, t·ªëc ƒë·ªô s·∫Ω "x√© gi√≥" so v·ªõi b·∫£n c≈©!**
Ch√†o b·∫°n, ƒë·ªÉ chuy·ªÉn m√£ ngu·ªìn n√†y sang x·ª≠ l√Ω **ƒêa lu·ªìng (Multi-threading)**, ch√∫ng ta c·∫ßn gi·∫£i quy·∫øt 2 v·∫•n ƒë·ªÅ quan tr·ªçng ƒë·ªÉ code ch·∫°y nhanh m√† kh√¥ng b·ªã l·ªói:

1. **Tranh ch·∫•p t√†i nguy√™n (Race Condition):** Khi nhi·ªÅu lu·ªìng c√πng mu·ªën vi·∫øt v√†o file `tiki_all.jsonl` ho·∫∑c c√πng ki·ªÉm tra bi·∫øn `SEEN` m·ªôt l√∫c, d·ªØ li·ªáu s·∫Ω b·ªã l·ªói ho·∫∑c ghi ƒë√® lung tung. -> **Gi·∫£i ph√°p:** D√πng `Lock` (Kh√≥a an to√†n).
2. **Qu·∫£n l√Ω lu·ªìng:** Thay v√¨ ch·∫°y v√≤ng l·∫∑p `for` t·ª´ tr√™n xu·ªëng d∆∞·ªõi, ta s·∫Ω t·∫°o m·ªôt danh s√°ch c√°c "Nhi·ªám v·ª•" (Task) v√† giao cho m·ªôt nh√≥m "C√¥ng nh√¢n" (Workers) l√†m c√πng l√∫c.

D∆∞·ªõi ƒë√¢y l√† ƒëo·∫°n code ƒë√£ ƒë∆∞·ª£c n√¢ng c·∫•p ho√†n ch·ªânh:

### Code Python ƒêa Lu·ªìng (Multi-threading)

```python
import requests
import time
import random
import os
import json
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
from schema_shared import ProductItem

print("üìÇ CWD =", os.getcwd())

# ================== CONFIG ==================
DATA_FOLDER = "data"
os.makedirs(DATA_FOLDER, exist_ok=True)
OUTPUT_FILE = os.path.join(DATA_FOLDER, "tiki_all.jsonl")

# C·∫§U H√åNH ƒêA LU·ªíNG
MAX_WORKERS = 5  # S·ªë lu·ªìng ch·∫°y c√πng l√∫c (Khuy√™n d√πng 5-10 ƒë·ªÉ tr√°nh b·ªã Tiki ch·∫∑n IP)
MAX_PAGES = 100  # S·ªë trang mu·ªën c√†o cho m·ªói danh m·ª•c

HEADERS = {
    "User-Agent": (
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
        "AppleWebKit/537.36 (KHTML, like Gecko) "
        "Chrome/120.0.0.0 Safari/537.36"
    ),
    "Accept": "application/json, text/plain, */*",
    "Accept-Language": "vi-VN,vi;q=0.9",
    "Referer": "https://tiki.vn/",
}

# T·∫†O KH√ìA AN TO√ÄN (LOCK)
# Lock n√†y gi√∫p ƒë·∫£m b·∫£o t·∫°i 1 th·ªùi ƒëi·ªÉm ch·ªâ c√≥ 1 lu·ªìng ƒë∆∞·ª£c ghi file v√† s·ª≠a SEEN
FILE_LOCK = threading.Lock()

SEEN = set()

# ================== H√ÄM H·ªñ TR·ª¢ ==================
def load_existing_data():
    if not os.path.exists(OUTPUT_FILE):
        return
    
    print(f"üîÑ ƒêang ƒë·ªçc d·ªØ li·ªáu c≈© t·ª´ {OUTPUT_FILE}...")
    count = 0
    try:
        with open(OUTPUT_FILE, "r", encoding="utf-8") as f:
            for line in f:
                try:
                    data = json.loads(line)
                    if "id" in data:
                        SEEN.add(data["id"])
                        count += 1
                except:
                    continue
    except Exception as e:
        print(f"‚ö†Ô∏è L·ªói ƒë·ªçc file c≈©: {e}")
    
    print(f"‚úÖ ƒê√£ t·∫£i {count} s·∫£n ph·∫©m c≈© v√†o b·ªô nh·ªõ (SEEN).")

def save_items_safe(items, category_name):
    """
    H√†m n√†y ch·ªãu tr√°ch nhi·ªám l·ªçc tr√πng v√† ghi file.
    ƒê∆∞·ª£c b·∫£o v·ªá b·ªüi FILE_LOCK ƒë·ªÉ tr√°nh 2 lu·ªìng ghi ƒë√® l√™n nhau.
    """
    new_items_count = 0
    
    # B·∫ÆT ƒê·∫¶U KH√ìA (C√°c lu·ªìng kh√°c ph·∫£i ƒë·ª©ng ch·ªù ·ªü ƒë√¢y)
    with FILE_LOCK:
        with open(OUTPUT_FILE, "a", encoding="utf-8") as f:
            for item in items:
                pid = f"tiki_{item.get('id')}"
                
                # Ki·ªÉm tra tr√πng l·∫∑p
                if pid in SEEN:
                    continue
                
                SEEN.add(pid) # Th√™m v√†o danh s√°ch ƒë√£ th·∫•y

                original_price = item.get("list_price") or item.get("price")

                product = ProductItem(
                    id=pid,
                    platform="tiki",
                    title=item.get("name", ""),
                    price=int(item.get("price", 0)),
                    original_price=int(original_price or 0),
                    url="https://tiki.vn/" + item.get("url_path", ""),
                    image_url=item.get("thumbnail_url", ""),
                    category=category_name,
                    brand=item.get("brand_name", "No Brand"),
                )

                f.write(product.to_json_line() + "\n")
                new_items_count += 1
    # K·∫æT TH√öC KH√ìA (Gi·∫£i ph√≥ng cho lu·ªìng kh√°c v√†o)
    
    return new_items_count

# ================== CRAWL 1 PAGE (WORKER) ==================
def crawl_single_page(category_name, category_id, page):
    """
    Nhi·ªám v·ª• c·ªßa 1 lu·ªìng: T·∫£i 1 trang c·ª• th·ªÉ v√† g·ªçi h√†m l∆∞u.
    """
    url = (
        "https://tiki.vn/api/personalish/v1/blocks/listings"
        f"?limit=40&include=advertisement"
        f"&aggregations=2&version=home-persionalized"
        f"&trackity_id=123&category={category_id}&page={page}"
    )

    try:
        # Sleep ng·∫´u nhi√™n ƒë·ªÉ gi·∫£m t·∫£i cho server (tr√°nh b·ªã ban)
        time.sleep(random.uniform(0.5, 2.0))
        
        # M·ªói lu·ªìng d√πng requests ri√™ng l·∫ª (ho·∫∑c t·∫°o session c·ª•c b·ªô n·∫øu c·∫ßn)
        resp = requests.get(url, headers=HEADERS, timeout=20)
        
        if resp.status_code != 200:
            return f"‚ö†Ô∏è {category_name} - Page {page}: HTTP {resp.status_code}"

        items = resp.json().get("data", [])
        if not items:
            return f"‚ö†Ô∏è {category_name} - Page {page}: Kh√¥ng c√≥ d·ªØ li·ªáu (H·∫øt trang?)"

        # G·ªçi h√†m l∆∞u an to√†n (Thread-safe save)
        added_count = save_items_safe(items, category_name)
        
        if added_count > 0:
            return f"‚úÖ {category_name} - Page {page}: Th√™m {added_count} m√≥n m·ªõi."
        else:
            return f"DATA {category_name} - Page {page}: 40 m√≥n ƒë√£ t·ªìn t·∫°i (Skip)."

    except Exception as e:
        return f"‚ùå {category_name} - Page {page}: L·ªói {str(e)}"

# ================== CATEGORY LIST ==================
TIKI_CATEGORIES = [
    {"name": "DODUNGPHONGNGU", "id": 8313},
    {"name": "NHABEP", "id": 1951},
    {"name": "PHONGAN", "id": 1954},
    {"name": "NOITHAT", "id": 2150},
    {"name": "TRANGTRINHACUA", "id": 1973},
]

# ================== MAIN ==================
if __name__ == "__main__":
    # 1. Load d·ªØ li·ªáu c≈©
    load_existing_data()

    # 2. T·∫°o danh s√°ch c√°c nhi·ªám v·ª• (Tasks)
    # Ch√∫ng ta s·∫Ω bi·∫øn v√≤ng l·∫∑p l·ªìng nhau th√†nh 1 danh s√°ch ph·∫≥ng
    all_tasks = []
    for cat in TIKI_CATEGORIES:
        for p in range(1, MAX_PAGES + 1):
            all_tasks.append((cat["name"], cat["id"], p))
    
    print(f"\nüöÄ B·∫ÆT ƒê·∫¶U CRAWL ƒêA LU·ªíNG")
    print(f"üëâ S·ªë lu·ªìng (Workers): {MAX_WORKERS}")
    print(f"üëâ T·ªïng s·ªë trang c·∫ßn x·ª≠ l√Ω: {len(all_tasks)}")
    print("-" * 50)

    # 3. Kh·ªüi t·∫°o Pool v√† ch·∫°y
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        # Submit t·∫•t c·∫£ task v√†o pool
        # future_to_page l√† t·ª´ ƒëi·ªÉn map gi·ªØa task ƒëang ch·∫°y v√† d·ªØ li·ªáu ƒë·∫ßu v√†o
        future_to_page = {
            executor.submit(crawl_single_page, t[0], t[1], t[2]): t 
            for t in all_tasks
        }
        
        # X·ª≠ l√Ω k·∫øt qu·∫£ khi t·ª´ng task ho√†n th√†nh (kh√¥ng c·∫ßn theo th·ª© t·ª±)
        for future in as_completed(future_to_page):
            try:
                result_message = future.result()
                print(result_message)
            except Exception as exc:
                print(f"‚ùå C√≥ l·ªói nghi√™m tr·ªçng trong lu·ªìng: {exc}")

    print("\nüéâ DONE ‚Äì TIKI UPDATE COMPLETED")
    print("üì¶ Total unique items in SEEN:", len(SEEN))

```

### Gi·∫£i th√≠ch nh·ªØng thay ƒë·ªïi quan tr·ªçng:

1. **`ThreadPoolExecutor`**: ƒê√¢y l√† "nh√† th·∫ßu" qu·∫£n l√Ω c√¥ng nh√¢n.
* M√¨nh set `MAX_WORKERS = 5`. Nghƒ©a l√† code s·∫Ω m·ªü 5 k·∫øt n·ªëi ƒë·∫øn Tiki c√πng m·ªôt l√∫c. Khi m·ªôt trang t·∫£i xong, lu·ªìng ƒë√≥ s·∫Ω l·∫≠p t·ª©c l·∫•y trang ti·∫øp theo trong danh s√°ch l√†m ti·∫øp.
* T·ªëc ƒë·ªô s·∫Ω nhanh g·∫•p ~5 l·∫ßn so v·ªõi code c≈©.


2. **`FILE_LOCK = threading.Lock()`**:
* Trong h√†m `save_items_safe`, m√¨nh d√πng l·ªánh `with FILE_LOCK:`.
* ƒêi·ªÅu n√†y b·∫Øt bu·ªôc c√°c lu·ªìng ph·∫£i **x·∫øp h√†ng** khi ghi file. N·∫øu Lu·ªìng A ƒëang ghi file, Lu·ªìng B ph·∫£i ƒë·ª©ng ch·ªù A xong m·ªõi ƒë∆∞·ª£c ghi. ƒêi·ªÅu n√†y ƒë·∫£m b·∫£o file `.jsonl` kh√¥ng b·ªã l·ªói d√≤ng hay m·∫•t d·ªØ li·ªáu.


3. **T√°ch logic Crawl v√† Save**:
* H√†m `crawl_single_page`: Ch·ªâ lo vi·ªác t·∫£i data t·ª´ m·∫°ng v·ªÅ (vi·ªác n√†y t·ªën th·ªùi gian nh·∫•t n√™n c·∫ßn ch·∫°y song song).
* H√†m `save_items_safe`: Ch·ªâ lo vi·ªác check tr√πng v√† l∆∞u (vi·ªác n√†y r·∫•t nhanh nh∆∞ng c·∫ßn an to√†n).



### L∆∞u √Ω khi ch·∫°y:

* N·∫øu th·∫•y m·∫°ng b·ªã l·ªói li√™n t·ª•c ho·∫∑c Tiki tr·∫£ v·ªÅ l·ªói HTTP 429 (Too Many Requests), h√£y gi·∫£m `MAX_WORKERS` xu·ªëng c√≤n `3` ho·∫∑c tƒÉng th·ªùi gian `time.sleep` l√™n.
* V·∫•n ƒë·ªÅ c·ªßa code c≈© l√† n√≥ **t·∫°o s·∫µn nhi·ªám v·ª• cho 100 trang** (Page 1 ƒë·∫øn 100) ngay t·ª´ ƒë·∫ßu. D√π trang 10 ƒë√£ h·∫øt h√†ng, n√≥ v·∫´n c·∫Øm ƒë·∫ßu ch·∫°y ti·∫øp trang 11, 12... ƒë·∫øn 100, g√¢y l√£ng ph√≠ th·ªùi gian v√† t√†i nguy√™n.

ƒê·ªÉ gi·∫£i quy·∫øt, ch√∫ng ta s·∫Ω d√πng k·ªπ thu·∫≠t **"C·ªù Hi·ªáu" (Flag)**.

### Gi·∫£i ph√°p logic:

1. T·∫°o m·ªôt bi·∫øn c·ªù hi·ªáu `STOP_FLAGS` ƒë·ªÉ theo d√µi tr·∫°ng th√°i c·ªßa t·ª´ng danh m·ª•c.
2. Khi m·ªôt lu·ªìng ph√°t hi·ªán trang web tr·∫£ v·ªÅ **r·ªóng** (h·∫øt h√†ng), n√≥ s·∫Ω **b·∫≠t c·ªù b√°o d·ª´ng** cho danh m·ª•c ƒë√≥.
3. C√°c lu·ªìng sau (v√≠ d·ª• ƒëang ƒë·ªãnh c√†o trang 50, 60...) tr∆∞·ªõc khi ch·∫°y s·∫Ω ng∆∞·ªõc l√™n nh√¨n c·ªù. N·∫øu th·∫•y c·ªù ƒë√£ b·∫≠t, n√≥ s·∫Ω **h·ªßy b·ªè ngay l·∫≠p t·ª©c** v√† chuy·ªÉn sang l√†m vi·ªác kh√°c.

D∆∞·ªõi ƒë√¢y l√† ƒëo·∫°n code ƒë√£ n√¢ng c·∫•p t√≠nh nƒÉng **"D·ª´ng th√¥ng minh"**:

```python
import requests
import time
import random
import os
import json
import threading
from concurrent.futures import ThreadPoolExecutor, as_completed
from schema_shared import ProductItem

print("üìÇ CWD =", os.getcwd())

# ================== CONFIG ==================
DATA_FOLDER = "data"
os.makedirs(DATA_FOLDER, exist_ok=True)
OUTPUT_FILE = os.path.join(DATA_FOLDER, "tiki_all.jsonl")

# C·∫§U H√åNH ƒêA LU·ªíNG
MAX_WORKERS = 5  
MAX_PAGES = 100 

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Accept": "application/json, text/plain, */*",
    "Referer": "https://tiki.vn/",
}

# C√ÅC KH√ìA AN TO√ÄN
FILE_LOCK = threading.Lock()
SEEN = set()

# [QUAN TR·ªåNG] Bi·∫øn to√†n c·ª•c ƒë·ªÉ l∆∞u tr·∫°ng th√°i d·ª´ng c·ªßa t·ª´ng Category
# V√≠ d·ª•: { 8313: False, 1951: True ... } -> True nghƒ©a l√† ƒë√£ h·∫øt trang, c·∫ßn d·ª´ng
STOP_FLAGS = {} 

# ================== H√ÄM H·ªñ TR·ª¢ ==================
def load_existing_data():
    if not os.path.exists(OUTPUT_FILE):
        return
    print(f"üîÑ ƒêang ƒë·ªçc d·ªØ li·ªáu c≈©...")
    count = 0
    try:
        with open(OUTPUT_FILE, "r", encoding="utf-8") as f:
            for line in f:
                try:
                    data = json.loads(line)
                    if "id" in data:
                        SEEN.add(data["id"])
                        count += 1
                except: continue
    except: pass
    print(f"‚úÖ ƒê√£ t·∫£i {count} s·∫£n ph·∫©m c≈© v√†o b·ªô nh·ªõ.")

def save_items_safe(items, category_name):
    new_items_count = 0
    with FILE_LOCK:
        with open(OUTPUT_FILE, "a", encoding="utf-8") as f:
            for item in items:
                pid = f"tiki_{item.get('id')}"
                if pid in SEEN: continue
                
                SEEN.add(pid)
                
                original_price = item.get("list_price") or item.get("price")
                product = ProductItem(
                    id=pid,
                    platform="tiki",
                    title=item.get("name", ""),
                    price=int(item.get("price", 0)),
                    original_price=int(original_price or 0),
                    url="https://tiki.vn/" + item.get("url_path", ""),
                    image_url=item.get("thumbnail_url", ""),
                    category=category_name,
                    brand=item.get("brand_name", "No Brand"),
                )
                f.write(product.to_json_line() + "\n")
                new_items_count += 1
    return new_items_count

# ================== WORKER (C√ì KI·ªÇM TRA D·ª™NG) ==================
def crawl_single_page(category_name, category_id, page):
    # 1. KI·ªÇM TRA C·ªú HI·ªÜU TR∆Ø·ªöC KHI CH·∫†Y
    # N·∫øu danh m·ª•c n√†y ƒë√£ b·ªã ƒë√°nh d·∫•u l√† "H·∫øt trang" (True), th√¨ b·ªè qua ngay
    if STOP_FLAGS.get(category_id) is True:
        return f"‚õî {category_name} - Page {page}: ƒê√£ d·ª´ng v√¨ h·∫øt trang tr∆∞·ªõc ƒë√≥."

    url = (
        "https://tiki.vn/api/personalish/v1/blocks/listings"
        f"?limit=40&include=advertisement"
        f"&aggregations=2&version=home-persionalized"
        f"&trackity_id=123&category={category_id}&page={page}"
    )

    try:
        time.sleep(random.uniform(0.5, 1.5)) # Sleep nh·∫π
        resp = requests.get(url, headers=HEADERS, timeout=15)
        
        if resp.status_code != 200:
            return f"‚ö†Ô∏è {category_name} - Page {page}: L·ªói HTTP {resp.status_code}"

        items = resp.json().get("data", [])
        
        # 2. LOGIC PH√ÅT HI·ªÜN H·∫æT TRANG
        if not items:
            # N·∫øu trang tr·∫£ v·ªÅ r·ªóng -> ƒê√°nh d·∫•u v√†o t·ª´ ƒëi·ªÉn to√†n c·ª•c l√† STOP
            STOP_FLAGS[category_id] = True
            return f"üõë {category_name} - Page {page}: R·ªñNG -> K√≠ch ho·∫°t d·ª´ng c√†o category n√†y!"

        # L∆∞u d·ªØ li·ªáu
        added = save_items_safe(items, category_name)
        return f"‚úÖ {category_name} - Page {page}: L·∫•y {len(items)}, M·ªõi {added}"

    except Exception as e:
        return f"‚ùå {category_name} - Page {page}: L·ªói {e}"

# ================== MAIN ==================
TIKI_CATEGORIES = [
    {"name": "DODUNGPHONGNGU", "id": 8313},
    {"name": "NHABEP", "id": 1951},
    {"name": "PHONGAN", "id": 1954},
    {"name": "NOITHAT", "id": 2150},
    {"name": "TRANGTRINHACUA", "id": 1973},
]

if __name__ == "__main__":
    load_existing_data()
    
    # Kh·ªüi t·∫°o c·ªù hi·ªáu: Ban ƒë·∫ßu t·∫•t c·∫£ ƒë·ªÅu ch∆∞a d·ª´ng (False)
    for cat in TIKI_CATEGORIES:
        STOP_FLAGS[cat["id"]] = False
    
    # T·∫°o danh s√°ch nhi·ªám v·ª•
    all_tasks = []
    for cat in TIKI_CATEGORIES:
        for p in range(1, MAX_PAGES + 1):
            all_tasks.append((cat["name"], cat["id"], p))
            
    print(f"\nüöÄ B·∫ÆT ƒê·∫¶U: {len(all_tasks)} trang d·ª± ki·∫øn (s·∫Ω d·ª´ng s·ªõm n·∫øu h·∫øt).")
    
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        future_to_page = {
            executor.submit(crawl_single_page, t[0], t[1], t[2]): t 
            for t in all_tasks
        }
        
        for future in as_completed(future_to_page):
            print(future.result())

    print("\nüéâ HO√ÄN TH√ÄNH - Code ƒë√£ t·ª± ƒë·ªông b·ªè qua c√°c trang th·ª´a.")
    print("üì¶ Total unique items:", len(SEEN))

```

### Gi·∫£i th√≠ch c∆° ch·∫ø ho·∫°t ƒë·ªông:

1. **Bi·∫øn `STOP_FLAGS**`: ƒê√¢y l√† m·ªôt cu·ªën s·ªï tay chung.
* V√≠ d·ª•: `STOP_FLAGS = {8313: False, 1951: False}` (Ban ƒë·∫ßu ch∆∞a ai d·ª´ng c·∫£).


2. **Khi g·∫∑p trang r·ªóng**:
* Gi·∫£ s·ª≠ Worker ƒëang ch·∫°y **Page 15** c·ªßa danh m·ª•c `8313` v√† th·∫•y k·∫øt qu·∫£ tr·∫£ v·ªÅ `[]` (r·ªóng).
* N√≥ s·∫Ω h√©t l√™n: "H·∫øt h√†ng r·ªìi!" b·∫±ng c√°ch g√°n `STOP_FLAGS[8313] = True`.


3. **D·ª´ng th√¥ng minh**:
* C√°c Worker kh√°c ƒëang chu·∫©n b·ªã ch·∫°y **Page 16, 17, 100...** c·ªßa danh m·ª•c `8313` s·∫Ω ki·ªÉm tra cu·ªën s·ªï tay n√†y tr∆∞·ªõc.
* Th·∫•y `True` -> N√≥ l·∫≠p t·ª©c tr·∫£ v·ªÅ `‚õî ƒê√£ d·ª´ng` m√† kh√¥ng c·∫ßn g·ª≠i request l√™n Tiki n·ªØa.
* Lu·ªìng ƒë√≥ r·∫£nh tay s·∫Ω chuy·ªÉn ngay sang l√†m danh m·ª•c kh√°c (v√≠ d·ª• `1951`).



C√°ch n√†y gi√∫p b·∫°n v·∫´n setup ch·∫°y 100 trang cho tho·∫£i m√°i, nh∆∞ng th·ª±c t·∫ø n·∫øu trang 10 h·∫øt th√¨ code s·∫Ω d·ª´ng ngay, kh√¥ng ch·∫°y oan 90 trang c√≤n l·∫°i.
N·∫øu b·∫°n crawl tr√πng data (t·ª©c l√† 1 s·∫£n ph·∫©m b·ªã ghi v√†o file 2 l·∫ßn), s·∫Ω c√≥ 3 h·∫≠u qu·∫£ ch√≠nh, nh∆∞ng **ƒë·ª´ng lo**, code hi·ªán t·∫°i c·ªßa b·∫°n ƒë√£ ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ **CH·∫∂N ƒê·ª®NG** vi·ªác n√†y.

D∆∞·ªõi ƒë√¢y l√† ph√¢n t√≠ch c·ª• th·ªÉ:

### 1. N·∫øu KH√îNG c√≥ c∆° ch·∫ø ch·ªëng tr√πng (H·∫≠u qu·∫£)

Gi·∫£ s·ª≠ b·∫°n b·ªè ƒëo·∫°n `if pid in SEEN` ƒëi, th√¨:

* **File ph√¨nh to v√¥ √≠ch:** File `tiki_all.jsonl` s·∫Ω ch·ª©a h√†ng ngh√¨n d√≤ng gi·ªëng h·ªát nhau. V√≠ d·ª• c√°i "N·ªìi c∆°m ƒëi·ªán Sharp" xu·∫•t hi·ªán 50 l·∫ßn. File n·∫∑ng 1GB nh∆∞ng th·ª±c ch·∫•t ch·ªâ c√≥ 100MB d·ªØ li·ªáu th·∫≠t.
* **Th·ªëng k√™ sai l·ªách:** Khi b·∫°n ƒë·∫øm s·ªë d√≤ng, b·∫°n t∆∞·ªüng m√¨nh c√≥ 60.000 s·∫£n ph·∫©m, nh∆∞ng th·ª±c t·∫ø ch·ªâ c√≥ 2.000 s·∫£n ph·∫©m l·∫∑p ƒëi l·∫∑p l·∫°i.
* **T·ªën th·ªùi gian x·ª≠ l√Ω sau n√†y:** Khi ƒëem data ƒëi ph√¢n t√≠ch ho·∫∑c train AI, b·∫°n l·∫°i m·∫•t c√¥ng vi·∫øt code ƒë·ªÉ l·ªçc l·∫°i t·ª´ ƒë·∫ßu.

---

### 2. Nh∆∞ng code hi·ªán t·∫°i c·ªßa b·∫°n ƒê√É AN TO√ÄN ‚úÖ

Trong ƒëo·∫°n code m√¨nh ƒë∆∞a cho b·∫°n (b·∫£n ƒëa lu·ªìng m·ªõi nh·∫•t), vi·ªác tr√πng data **kh√¥ng th·ªÉ x·∫£y ra** nh·ªù "3 l·ªõp b·∫£o v·ªá":

#### üõ°Ô∏è L·ªõp 1: Kh√¥i ph·ª•c tr√≠ nh·ªõ (`load_existing_data`)

Ngay khi b·∫•m ch·∫°y, code l√†m vi·ªác n√†y ƒë·∫ßu ti√™n:

```python
# ƒê·ªçc file c≈©, n·∫°p to√†n b·ªô ID ƒë√£ c√≥ v√†o RAM
load_existing_data()

```

üëâ N·∫øu h√¥m qua b·∫°n ƒë√£ c√†o c√°i "Ly gi·ªØ nhi·ªát (ID: 123)", th√¨ h√¥m nay bi·∫øn `SEEN` ƒë√£ ch·ª©a s·ªë `123`.

#### üõ°Ô∏è L·ªõp 2: B·ªô l·ªçc th·ªùi gian th·ª±c (`SEEN` set)

Khi code ch·∫°y, tr∆∞·ªõc khi ghi b·∫•t c·ª© th·ª© g√¨ xu·ªëng file, n√≥ ƒë·ªÅu h·ªèi:

```python
if pid in SEEN:
    continue  # <--- N·∫øu th·∫•y ID n√†y quen quen (ƒë√£ c√≥ trong RAM), B·ªé QUA NGAY!

```

üëâ D√π Tiki c√≥ c·ªë t√¨nh hi·ªÉn th·ªã l·∫°i s·∫£n ph·∫©m c≈© ·ªü trang kh√°c, code c≈©ng s·∫Ω ph·ªõt l·ªù n√≥.

#### üõ°Ô∏è L·ªõp 3: Kh√≥a an to√†n (`FILE_LOCK`)

V√¨ b·∫°n ch·∫°y ƒëa lu·ªìng (5 ng∆∞·ªùi l√†m c√πng l√∫c), s·ª£ nh·∫•t l√† 2 ng∆∞·ªùi c√πng t√¨m th·∫•y 1 s·∫£n ph·∫©m m·ªõi c√πng 1 t√≠ch t·∫Øc.

```python
with FILE_LOCK:
    if pid in SEEN: continue # Ki·ªÉm tra l·∫ßn cu·ªëi c·ª±c k·ªπ
    SEEN.add(pid)
    f.write(...)

```

üëâ C√°i kh√≥a `FILE_LOCK` b·∫Øt c√°c lu·ªìng ph·∫£i x·∫øp h√†ng. Ng∆∞·ªùi n√†y check xong, ghi xong, ng∆∞·ªùi kia m·ªõi ƒë∆∞·ª£c v√†o. Kh√¥ng bao gi·ªù c√≥ chuy·ªán 2 lu·ªìng ghi c√πng 1 s·∫£n ph·∫©m.

---

### 3. Tr∆∞·ªùng h·ª£p duy nh·∫•t b·ªã tr√πng (L∆∞u √Ω)

Code ch·ªâ b√≥ tay n·∫øu b·∫°n **m·ªü 2 c·ª≠a s·ªï CMD v√† ch·∫°y 2 file code c√πng m·ªôt l√∫c**.

* L√∫c ƒë√≥, c·ª≠a s·ªï A kh√¥ng bi·∫øt c·ª≠a s·ªï B ƒëang l√†m g√¨ (v√¨ 2 bi·∫øn `SEEN` n·∫±m ·ªü 2 v√πng nh·ªõ RAM kh√°c nhau).
* **L·ªùi khuy√™n:** Ch·ªâ ch·∫°y **1 file script** t·∫°i 1 th·ªùi ƒëi·ªÉm th√¥i nh√©.

**T√≥m l·∫°i:** V·ªõi code hi·ªán t·∫°i, b·∫°n c·ª© y√™n t√¢m ch·∫°y ti·∫øp, file k·∫øt qu·∫£ ƒë·∫£m b·∫£o **S·∫°ch - ƒê·ªôc nh·∫•t (Unique) - Kh√¥ng tr√πng l·∫∑p**.
Ch√≠nh x√°c 100%! B·∫°n hi·ªÉu ho√†n to√†n ƒë√∫ng v·∫•n ƒë·ªÅ r·ªìi ƒë√≥.

ƒê·ªÉ m√¨nh gi·∫£i th√≠ch k·ªπ h∆°n c∆° ch·∫ø b√™n d∆∞·ªõi d√≤ng th√¥ng b√°o ƒë√≥:

`[thoi-trang-nu] - Page 5: L·∫•y 40, M·ªõi 0`

1. **"L·∫•y 40":** Nghƒ©a l√† code c·ªßa b·∫°n ƒë√£ g·ª≠i y√™u c·∫ßu th√†nh c√¥ng l√™n Tiki v√† Tiki tr·∫£ v·ªÅ danh s√°ch **40 s·∫£n ph·∫©m** n·∫±m ·ªü trang s·ªë 5.
2. **"M·ªõi 0":**
* Code c·∫ßm 40 s·∫£n ph·∫©m ƒë√≥, l·∫ßn l∆∞·ª£t so s√°nh ID c·ªßa t·ª´ng c√°i v·ªõi danh s√°ch `SEEN` (d·ªØ li·ªáu c≈© ƒë√£ n·∫°p v√†o RAM).
* K·∫øt qu·∫£ l√†: **C·∫£ 40 s·∫£n ph·∫©m n√†y ƒë·ªÅu ƒê√É T·ªíN T·∫†I** trong file c·ªßa b·∫°n r·ªìi.
* H√†nh ƒë·ªông: Code **b·ªè qua**, kh√¥ng ghi th√™m d√≤ng n√†o v√†o file c·∫£ ƒë·ªÉ tr√°nh b·ªã tr√πng l·∫∑p.



---

### üí° ƒêi·ªÅu n√†y b√°o hi·ªáu g√¨?

Vi·ªác b·∫°n th·∫•y h√†ng lo·∫°t d√≤ng xanh l√° c√¢y `L·∫•y 40, M·ªõi 0` li√™n t·ª•c (nh∆∞ trong ·∫£nh b·∫°n g·ª≠i) ch·ª©ng t·ªè:

1. **D·ªØ li·ªáu v√πng n√†y ƒë√£ "b√£o h√≤a":** B·∫°n ƒë√£ c√†o s·∫°ch s√†nh sanh 2.000 s·∫£n ph·∫©m hi·ªÉn th·ªã c·ªßa danh m·ª•c `thoi-trang-nu` (ID 931) r·ªìi.
2. **Code ƒëang ch·∫°y l√£ng ph√≠:** N√≥ v·∫´n t·ªën c√¥ng t·∫£i v·ªÅ, t·ªën c√¥ng so s√°nh, nh∆∞ng kh√¥ng thu ho·∫°ch ƒë∆∞·ª£c g√¨ m·ªõi.

üëâ **Gi·∫£i ph√°p ngay l·∫≠p t·ª©c:**
B·∫°n c·∫ßn d·ª´ng code l·∫°i v√† √°p d·ª•ng chi·∫øn thu·∫≠t **"Chia nh·ªè danh m·ª•c"** (Crawl Sub-categories) m√† m√¨nh ƒë√£ h∆∞·ªõng d·∫´n ·ªü c√¢u tr·∫£ l·ªùi tr∆∞·ªõc (d√πng script `get_all_categories.py`).

Ch·ªâ khi b·∫°n thay ID to (`931`) b·∫±ng c√°c ID nh·ªè (v√≠ d·ª•: `Ao-thun-nu`, `Vay-dam`...), b·∫°n m·ªõi th·∫•y con s·ªë `M·ªõi` nh·∫£y l√™n `40` tr·ªü l·∫°i!

---
